<!-- RULEBOOK:START -->
# Project Rules

Generated by @hivellm/rulebook
Generated at: 2026-02-27T12:26:26.827Z

## ‚ö†Ô∏è CRITICAL: Task Management Rules (HIGHEST PRECEDENCE)

**MANDATORY**: All task creation MUST follow Rulebook task management system.

**üìã ALWAYS reference `/.rulebook/specs/RULEBOOK.md` FIRST before creating any tasks.**

**Rules from RULEBOOK.md take precedence over all other rules in this file.**

**Key Requirements:**
- ‚úÖ Context7 MCP is REQUIRED for task creation
- ‚úÖ All tasks MUST follow Rulebook task format
- ‚úÖ Use `rulebook task create` to create tasks
- ‚úÖ Always validate task format before committing
- ‚ùå NEVER create tasks without checking RULEBOOK.md format requirements

### ‚ö†Ô∏è CRITICAL: Task File Structure Rules

**MANDATORY**: When creating or updating tasks, you MUST follow the correct file structure:

**‚úÖ CORRECT File Structure:**
- `proposal.md` - **Why** and **What Changes** (detailed explanations go here)
- `tasks.md` - **ONLY checklist items** (simple `- [ ]` or `- [x]` format)
- `specs/<module>/spec.md` - **Technical specifications** (SHALL/MUST requirements)
- `design.md` - **Technical design decisions** (optional, for complex features)

**‚ùå FORBIDDEN Practices:**
- ‚ùå **NEVER** add long explanations or specifications in `tasks.md`
- ‚ùå **NEVER** put technical details in `tasks.md` (use `specs/` instead)
- ‚ùå **NEVER** create `README.md` or `README` files in task directories
- ‚ùå **NEVER** create `PROCESS.md` or `PROCESS` files in task directories
- ‚ùå **NEVER** create any file not listed in the correct structure above

**What Goes Where:**

1. **`proposal.md`** - Use for:
   - Detailed "Why" explanations (minimum 20 characters)
   - "What Changes" descriptions
   - Impact analysis
   - Business/technical rationale

2. **`tasks.md`** - Use ONLY for:
   - Simple checklist items: `- [ ] Task description`
   - Status updates: `- [x] Completed task`
   - Brief comments: `<!-- tested, coverage: 95% -->`
   - **DO NOT** add long explanations, specifications, or technical details here

3. **`specs/<module>/spec.md`** - Use for:
   - Technical specifications with SHALL/MUST requirements
   - Scenario definitions (Given/When/Then)
   - Delta operations (ADDED/MODIFIED/REMOVED)
   - All detailed technical requirements

4. **`design.md`** - Use for (optional):
   - Architecture decisions
   - Technical design rationale
   - Complex implementation details

**Example of WRONG usage:**
```markdown
# tasks.md (WRONG - too much detail)

## Implementation
- [ ] Create authentication system
  The system SHALL implement JWT-based authentication...
  Users MUST be able to login with email and password...
  The system MUST validate tokens...
```

**Example of CORRECT usage:**
```markdown
# tasks.md (CORRECT - simple checklist)

## 1. Implementation Phase
- [ ] 1.1 Create authentication module
- [ ] 1.2 Add JWT token generation
- [ ] 1.3 Implement password validation

# specs/auth/spec.md (CORRECT - specifications here)

## ADDED Requirements

### Requirement: Authentication System
The system SHALL implement JWT-based authentication.

#### Scenario: User Login
Given a user with valid credentials
When the user submits login form
Then the system MUST return a JWT token
```

**Remember:**
- ‚úÖ `tasks.md` = Simple checklist only
- ‚úÖ `proposal.md` = Why and what changes
- ‚úÖ `specs/` = Technical specifications
- ‚ùå No README, PROCESS, or other files

**For complete task management guidelines, see: `/.rulebook/specs/RULEBOOK.md`**

---

## Core Rules

This project uses @hivellm/rulebook standards.

**CRITICAL RULES:**
1. **ALWAYS check `RULEBOOK.md` first** when creating tasks
2. Write tests first (95%+ coverage required)
3. Run quality checks before committing:
   - Type check / Compiler check
   - Linter (no warnings allowed)
   - All tests (100% pass rate)
   - Coverage check
4. Update docs/ when implementing features
5. Follow strict documentation structure
6. **NEVER run destructive deletions (`rm -rf`) in this repository; when adding submodules always use `git submodule add`.**
7. **Temporary files and scripts**:
   - ‚úÖ ALL scripts MUST be created in `/scripts` directory
   - ‚úÖ ALL temporary files (test, log, debug) MUST be in `/scripts`
   - ‚úÖ ALL temporary files MUST be removed immediately after use (MANDATORY)
   - ‚ùå NEVER create temporary files in project root or outside `/scripts`
   - ‚ùå NEVER leave temporary files after use - clean up before committing

## Detailed Rules

For comprehensive rules, see the corresponding files in `/.rulebook/specs/`:

- `/.rulebook/specs/RULEBOOK.md` - **Task management rules (HIGHEST PRECEDENCE)**
- `/.rulebook/specs/QUALITY_ENFORCEMENT.md` - Quality enforcement rules
- `/.rulebook/specs/GIT.md` - Git workflow rules

Language-specific rules are in `/.rulebook/specs/`.
Module-specific patterns are in `/.rulebook/specs/`.

## Persistent Memory System

This project uses a **persistent memory system** with hybrid BM25+vector search.
Memory is **enabled by default** and persists across sessions for maintaining context and preserving learnings.

**MANDATORY: You MUST actively use memory to preserve context and learnings.**

**Status**: ‚úÖ Enabled by default in `.rulebook` configuration

### Key Features

- **Rich Contextual Summaries**: Memories auto-extract summaries with key concepts, decisions, patterns, gotchas
- **Hybrid Search**: BM25 keyword search + HNSW vector semantic search for relevant results
- **3-Layer Search Pattern**: Compact results ‚Üí Timeline context ‚Üí Full details (token-efficient)
- **Auto-Capture**: Implementation outputs from AI agents automatically captured
- **Zero Native Dependencies**: Pure WASM + TypeScript, works on all platforms

### When to Save to Memory

Save to memory whenever you:
- **Make an architectural decision** ‚Äî why you chose one approach over another
- **Fix a bug** ‚Äî root cause and how it was resolved
- **Discover something important** ‚Äî codebase patterns, gotchas, constraints
- **Implement a feature** ‚Äî design approach, patterns discovered, edge cases handled
- **Encounter an error** ‚Äî root cause and solution for future reference
- **Receive user preferences** ‚Äî coding style, conventions, workflow preferences
- **Complete a task or session** ‚Äî summarize what was accomplished and learnings

### How to Save Memory

Save memories with rich context for better future searches:

**Via MCP:**
```
rulebook_memory_save({
  type: "feature|decision|bugfix|discovery|refactor|change|observation",
  title: "Short title (‚â§80 chars)",
  content: "Detailed explanation: what was done, why, key decisions, patterns, gotchas...",
  tags: ["relevant", "tags"]
})
```

**Via CLI:**
```bash
rulebook memory save "Detailed content here" --type feature --title "Brief Title" --tags tag1,tag2
```

**Summary Auto-Extraction**: Summaries are automatically extracted from content, capturing:
- Key concepts and decisions
- Design patterns discovered
- Gotchas and edge cases
- Problem/solution context

### When and How to Search Memory

**At the START of every session**, search memory for relevant context:

**Via MCP (3-Layer Search - token efficient):**
```
Layer 1 - Compact search: rulebook_memory_search({ query: "your topic", mode: "hybrid", limit: 10 })
  ‚Üí Returns: id, title, type, score, summary (compact results)
Layer 2 - Timeline: rulebook_memory_timeline({ memoryId: "abc-123", window: 5 })
  ‚Üí Returns: 5 before/after chronologically
Layer 3 - Full details: rulebook_memory_get({ ids: ["abc-123"] })
  ‚Üí Returns: complete memory objects
```

**Via CLI:**
```bash
rulebook memory search "authentication" --mode hybrid          # Keyword + semantic
rulebook memory search "oauth" --type feature                  # Filter by memory type
rulebook memory list --limit 10                               # Recent memories
```

Also search when:
- Working on code you've touched before
- The user references a past discussion or decision
- You need context about why something was done a certain way
- **Before implementing similar features** ‚Äî find past patterns and gotchas

### Session Workflow

**Complete memory-enhanced workflow:**
1. **Start of session**: Search memory for relevant past context
2. **During work**: Save discoveries, patterns, decisions as they happen
3. **After feature**: Save complete implementation with summaries
4. **End of session**: Save session summary for future sessions

### Session Summary

Before ending a session or when context is getting long, save a summary:
```
type: observation
title: "Session summary: <date or topic>"
content: "Accomplished: ... | Pending: ... | Key decisions: ..."
```

When in doubt, ask to review @AGENTS.md first.

## Ralph Autonomous Loop

This project is **enabled for Ralph autonomous loop** for iterative feature implementation.
Ralph automates multi-iteration development with fresh AI context per iteration, persisting learnings via git and progress logs.

**Status**: ‚úÖ Enabled by default in `.rulebook` configuration

### Quick Start

```bash
# 1. Create tasks
rulebook task create <task-id>

# 2. Initialize Ralph
rulebook ralph init

# 3. Run autonomous loop
rulebook ralph run --max-iterations 10

# 4. Monitor progress
rulebook ralph status
rulebook ralph history
```

### Key Commands

- `rulebook ralph init` ‚Äî Initialize Ralph configuration and create PRD from tasks
- `rulebook ralph run [--max-iterations N] [--tool claude|amp]` ‚Äî Execute autonomous loop
- `rulebook ralph status` ‚Äî Show loop progress and current iteration
- `rulebook ralph history` ‚Äî Display iteration history and learnings
- `rulebook ralph pause` ‚Äî Gracefully pause autonomous loop
- `rulebook ralph resume` ‚Äî Resume from paused state

For detailed Ralph documentation, see `templates/skills/workflows/ralph/SKILL.md`

<!-- RULEBOOK:END -->

## Language-Specific Rules

The following languages are configured for this project. For detailed rules, see the corresponding files in `/.rulebook/specs/`:

### Cpp Development Rules

For comprehensive Cpp-specific guidelines, see `/.rulebook/specs/CPP.md`

Quick reference:
- Type safety and strict mode
- Code quality standards
- Testing requirements (95%+ coverage)
- Package management
- Error handling patterns

**Usage**: When working with language-specific code, reference the corresponding `/.rulebook/specs/[LANGUAGE].md` file for detailed guidelines.

## Module-Specific Instructions

The following modules are configured for this project. For detailed instructions, see the corresponding files in `/.rulebook/specs/`:

### Agent automation Instructions

For comprehensive Agent automation-specific instructions, see `/.rulebook/specs/AGENT_AUTOMATION.md`

Quick reference:
- Module-specific instructions
- Usage guidelines
- Integration patterns

**Usage**: When working with module-specific features, reference the corresponding `/.rulebook/specs/[MODULE].md` file for detailed instructions.

## Project Capabilities

This project has the following AI-assisted capabilities enabled:

- **Core**: Agent Automation, DAG Workflow, Documentation Rules, Quality Enforcement, Rulebook Task Management, Agent Automation, Dag, Documentation Rules, Quality Enforcement, Ralph, Rulebook
- **Languages**: C, C++, C#, C, Cpp

Use `rulebook skill list` to see all available skills.
Use `rulebook skill add <skill-id>` to enable additional skills.

<!-- RULEBOOK:SKILLS_INDEX:START -->
## Installed Skills

| Category | Skill | Description |
|----------|-------|-------------|
| Core | Agent Automation | Mandatory workflow that AI agents MUST execute after EVERY implementation. |
| Core | DAG Workflow | Maintain a clean dependency graph (DAG) to prevent circular dependencies and ensure maintainable architecture. |
| Core | Documentation Rules | All documentation in English. Root README concise, detailed docs in `/docs`. |
| Core | Quality Enforcement | These rules are NON-NEGOTIABLE and MUST be followed without exception. |
| Core | Rulebook Task Management | Spec-driven task management for features and breaking changes with OpenSpec-compatible format |
| Languages | C | Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow). |
| Languages | C++ | Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow). |
| Languages | C# | Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow). |
| Languages | C | **CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow). |
| Languages | Cpp | **CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow). |
| Core | Agent Automation | **CRITICAL**: Mandatory workflow that AI agents MUST execute after EVERY implementation. |
| Core | Dag | **CRITICAL**: Maintain a clean dependency graph (DAG) to prevent circular dependencies and ensure maintainable architecture. |
| Core | Documentation Rules | **CRITICAL**: All documentation in English. Root README concise, detailed docs in `/docs`. |
| Core | Quality Enforcement | **CRITICAL**: These rules are NON-NEGOTIABLE and MUST be followed without exception. |
| Core | Ralph | Ralph is an autonomous AI agent loop that iteratively solves tasks with fresh context for each iteration. This document explains how to use Ralph with |
| Core | Rulebook | **CRITICAL**: Use Rulebook's built-in task management system for spec-driven development of new features and breaking changes. |

<!-- RULEBOOK:SKILLS_INDEX:END -->

<!-- RULEBOOK:SKILL:core/agent-automation:START -->
<!-- AGENT_AUTOMATION:START -->
# Agent Automation Rules

**CRITICAL**: Mandatory workflow that AI agents MUST execute after EVERY implementation.

## Workflow Overview

After completing ANY feature, bug fix, or code change, execute this workflow in order:

### Step 1: Quality Checks (MANDATORY)

Run these checks in order - ALL must pass:

```bash
1. Type check (if applicable)
2. Lint (MUST pass with ZERO warnings)
3. Format code
4. Run ALL tests (MUST pass 100%)
5. Verify coverage meets threshold (default 95%)
```

**Language-specific commands**: See your language template (TYPESCRIPT, RUST, PYTHON, etc.) for exact commands.

**IF ANY CHECK FAILS:**
- ‚ùå STOP immediately
- ‚ùå DO NOT proceed
- ‚ùå DO NOT commit
- ‚úÖ Fix the issue first
- ‚úÖ Re-run ALL checks

### Step 2: Security & Dependency Audits

```bash
# Check for vulnerabilities (language-specific)
# Check for outdated dependencies (informational)
# Find unused dependencies (optional)
```

**Language-specific commands**: See your language template for audit commands.

**IF VULNERABILITIES FOUND:**
- ‚úÖ Attempt automatic fix
- ‚úÖ Document if auto-fix fails
- ‚úÖ Include in Step 5 report
- ‚ùå Never ignore critical/high vulnerabilities without user approval

### Step 3: Update OpenSpec Tasks

If `openspec/` directory exists:

```bash
# Mark completed tasks as [DONE]
# Update in-progress tasks
# Add new tasks if discovered
# Update progress percentages
# Document deviations or blockers
```

### Step 4: Update Documentation

```bash
# Update ROADMAP.md (if feature is milestone)
# Update CHANGELOG.md (conventional commits format)
# Update feature specs (if implementation differs)
# Update README.md (if public API changed)
```

### Step 5: Git Commit

**ONLY after ALL above steps pass:**

**‚ö†Ô∏è CRITICAL: All commit messages MUST be in English**

```bash
git add .
git commit -m "<type>(<scope>): <description>

- Detailed change 1
- Detailed change 2
- Tests: [describe coverage]
- Coverage: X% (threshold: 95%)

Closes #<issue> (if applicable)"
```

**Commit Types**: `feat`, `fix`, `docs`, `refactor`, `perf`, `test`, `build`, `ci`, `chore`

**Language Requirement**: Commit messages must be written in English. Never use Portuguese, Spanish, or any other language.

### Step 6: Report to User

```
‚úÖ Implementation Complete

üìù Changes:
- [List main changes]

üß™ Quality Checks:
- ‚úÖ Type check: Passed
- ‚úÖ Linting: Passed (0 warnings)
- ‚úÖ Formatting: Applied
- ‚úÖ Tests: X/X passed (100%)
- ‚úÖ Coverage: X% (threshold: 95%)

üîí Security:
- ‚úÖ No vulnerabilities

üìä OpenSpec:
- ‚úÖ Tasks updated
- ‚úÖ Progress: X% ‚Üí Y%

üìö Documentation:
- ‚úÖ CHANGELOG.md updated
- ‚úÖ [other docs updated]

üíæ Git:
- ‚úÖ Committed: <commit message>
- ‚úÖ Hash: <commit hash>

üìã Next Steps:
- [ ] Review changes
- [ ] Push to remote (if ready)
```

## Automation Exceptions

Skip steps ONLY when:

1. **Exploratory Code**: User says "experimental", "draft", "try"
   - Still run quality checks
   - Don't commit

2. **User Explicitly Requests**: User says "skip tests", "no commit"
   - Only skip requested step
   - Warn about skipped steps

3. **Emergency Hotfix**: Critical production bug
   - Run minimal checks
   - Document technical debt

**In ALL other cases: Execute complete workflow**

## Error Recovery

If workflow fails 3+ times:

```bash
1. Create backup branch
2. Reset to last stable commit
3. Report to user with error details
4. Request guidance or try alternative approach
```

## Best Practices

### DO's ‚úÖ
- ALWAYS run complete workflow
- ALWAYS update OpenSpec and documentation
- ALWAYS use conventional commits
- ALWAYS report summary to user
- ASK before skipping steps

### DON'Ts ‚ùå
- NEVER skip quality checks without permission
- NEVER commit failing tests
- NEVER commit linting errors
- NEVER skip documentation updates
- NEVER assume user wants to skip automation
- NEVER commit debug code or secrets

## Summary

**Complete workflow after EVERY implementation:**

1. ‚úÖ Quality checks (type, lint, format, test, coverage)
2. ‚úÖ Security audit
3. ‚úÖ Update OpenSpec tasks
4. ‚úÖ Update documentation
5. ‚úÖ Git commit (conventional format)
6. ‚úÖ Report summary to user

**Only skip with explicit user permission and document why.**

<!-- AGENT_AUTOMATION:END -->

<!-- RULEBOOK:SKILL:core/agent-automation:END -->

<!-- RULEBOOK:SKILL:core/dag-workflow:START -->
<!-- DAG:START -->
# Dependency Architecture Guidelines (DAG)

**CRITICAL**: Maintain a clean dependency graph (DAG) to prevent circular dependencies and ensure maintainable architecture.

## Core Principles

### No Circular Dependencies
- **NEVER** create circular dependencies between components
- **ALWAYS** ensure dependencies form a Directed Acyclic Graph (DAG)
- **ALWAYS** validate dependency structure before committing

### Layer Separation
- **ALWAYS** maintain clear layer boundaries
- **ALWAYS** ensure higher layers depend only on lower layers
- **NEVER** allow lower layers to depend on higher layers

### Interface Boundaries
- **ALWAYS** use interfaces for cross-component communication
- **ALWAYS** define clear contracts between components
- **NEVER** create tight coupling between components

## Dependency Rules

### Layer Architecture

**Layer 1: Foundation**
- Utils, helpers, utilities
- Type definitions
- Configuration management
- Base constants and enums

**Layer 2: Core**
- Core business logic
- Data models and schemas
- Base services and repositories
- Domain entities

**Layer 3: Features**
- Feature implementations
- Business logic
- API endpoints
- Service orchestration

**Layer 4: Presentation**
- UI components
- CLI interfaces
- API controllers
- View models

### Dependency Flow

```
Foundation ‚Üí Core ‚Üí Features ‚Üí Presentation
```

**Rules:**
- ‚úÖ Foundation can depend on nothing (or external libraries only)
- ‚úÖ Core can depend on Foundation
- ‚úÖ Features can depend on Core and Foundation
- ‚úÖ Presentation can depend on Features, Core, and Foundation
- ‚ùå Foundation CANNOT depend on Core, Features, or Presentation
- ‚ùå Core CANNOT depend on Features or Presentation
- ‚ùå Features CANNOT depend on Presentation

## Component Graph Structure

### Example Valid DAG

```
Core
  ‚îú‚îÄ‚îÄ Utils
  ‚îú‚îÄ‚îÄ Types
  ‚îî‚îÄ‚îÄ Config

Features
  ‚îú‚îÄ‚îÄ Feature A
  ‚îÇ   ‚îî‚îÄ‚îÄ Core
  ‚îî‚îÄ‚îÄ Feature B
      ‚îú‚îÄ‚îÄ Core
      ‚îî‚îÄ‚îÄ Feature A

Presentation
  ‚îú‚îÄ‚îÄ CLI
  ‚îÇ   ‚îî‚îÄ‚îÄ Features
  ‚îî‚îÄ‚îÄ API
      ‚îî‚îÄ‚îÄ Features
```

### Invalid Patterns (Circular Dependencies)

```
‚ùå Feature A ‚Üí Feature B ‚Üí Feature A
‚ùå Core ‚Üí Feature ‚Üí Core
‚ùå Utils ‚Üí Core ‚Üí Utils
```

## Verification

### Before Committing

**MANDATORY**: Verify dependency structure:

```bash
# Check for circular dependencies
# Add your dependency check command here
# Examples:
# - TypeScript: tsc --noEmit (catches import cycles)
# - Rust: cargo check (catches circular dependencies)
# - Python: pylint --disable=all --enable=import-error
# - Go: go vet ./...
```

### Dependency Analysis Tools

**TypeScript/JavaScript:**
```bash
# Use madge to detect circular dependencies
npx madge --circular src/

# Use dependency-cruiser
npx dependency-cruiser --validate src/
```

**Rust:**
```bash
# Cargo automatically detects circular dependencies
cargo check
```

**Python:**
```bash
# Use vulture or pylint
pylint --disable=all --enable=import-error src/
```

**Go:**
```bash
# Use go vet
go vet ./...
```

## Best Practices

### DO's ‚úÖ

- **ALWAYS** maintain clear layer boundaries
- **ALWAYS** validate dependencies before committing
- **ALWAYS** use interfaces for cross-layer communication
- **ALWAYS** document component dependencies
- **ALWAYS** refactor when circular dependencies are detected
- **ALWAYS** keep dependency graph shallow (avoid deep nesting)

### DON'Ts ‚ùå

- **NEVER** create circular dependencies
- **NEVER** allow lower layers to depend on higher layers
- **NEVER** create tight coupling between components
- **NEVER** skip dependency validation
- **NEVER** mix concerns across layers
- **NEVER** create bidirectional dependencies

## Dependency Documentation

### Documenting Dependencies

**In code:**
```typescript
// Component: UserService
// Dependencies:
//   - UserRepository (Core layer)
//   - Logger (Foundation layer)
//   - Config (Foundation layer)
// Does NOT depend on:
//   - UserController (Presentation layer)
//   - UserAPI (Presentation layer)
```

**In documentation:**
- Maintain `docs/DAG.md` with component dependency graph
- Update when adding new components
- Include dependency direction and purpose

## Refactoring Circular Dependencies

### When Circular Dependency is Detected

1. **Identify the cycle**: Map the dependency chain
2. **Find common dependency**: Extract shared functionality
3. **Introduce interface**: Use dependency inversion
4. **Restructure layers**: Move components to appropriate layer
5. **Validate fix**: Run dependency check again

### Example Refactoring

**Before (Circular):**
```
Feature A ‚Üí Feature B ‚Üí Feature A
```

**After (Fixed):**
```
Core
  ‚îî‚îÄ‚îÄ SharedService

Feature A ‚Üí Core
Feature B ‚Üí Core
```

## Integration with AGENT_AUTOMATION

**CRITICAL**: Include dependency validation in AGENT_AUTOMATION workflow:

```bash
# Step 1.5: Dependency Validation (before implementation)
# Check for circular dependencies
npm run check-deps  # or equivalent for your language

# If circular dependencies detected:
# ‚ùå STOP - Fix architecture first
# ‚úÖ Refactor to remove cycles
# ‚úÖ Re-validate before proceeding
```

## Language-Specific Guidelines

### TypeScript/JavaScript
- Use `madge` or `dependency-cruiser` for validation
- Configure ESLint rules for import ordering
- Use path aliases to enforce layer structure

### Rust
- Cargo automatically detects circular dependencies
- Use `cargo tree` to visualize dependencies
- Organize modules to reflect layer structure

### Python
- Use `pylint` or `vulture` for import analysis
- Organize packages to reflect layer structure
- Use `__init__.py` to control exports

### Go
- Use `go vet` for dependency validation
- Organize packages in directories reflecting layers
- Use interfaces to decouple components

## Examples

### Good Architecture ‚úÖ

```
src/
‚îú‚îÄ‚îÄ foundation/
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ repositories/
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (depends on core, foundation)
‚îÇ   ‚îî‚îÄ‚îÄ payments/
‚îÇ       ‚îî‚îÄ‚îÄ (depends on core, foundation)
‚îî‚îÄ‚îÄ presentation/
    ‚îú‚îÄ‚îÄ cli/
    ‚îÇ   ‚îî‚îÄ‚îÄ (depends on features, core, foundation)
    ‚îî‚îÄ‚îÄ api/
        ‚îî‚îÄ‚îÄ (depends on features, core, foundation)
```

### Bad Architecture ‚ùå

```
src/
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îî‚îÄ‚îÄ auth/
‚îÇ       ‚îî‚îÄ‚îÄ (depends on presentation)  # ‚ùå Wrong direction
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ (depends on features)  # ‚ùå Wrong direction
‚îî‚îÄ‚îÄ presentation/
    ‚îî‚îÄ‚îÄ (depends on foundation only)  # ‚ùå Missing dependencies
```

## Maintenance

### Regular Checks

- **Before every commit**: Run dependency validation
- **Weekly**: Review dependency graph for optimization
- **Before major refactoring**: Document current dependencies
- **After adding new components**: Update DAG documentation

### Tools Integration

Add dependency checks to:
- Pre-commit hooks
- CI/CD pipelines
- AGENT_AUTOMATION workflow
- Quality gates

<!-- DAG:END -->


<!-- RULEBOOK:SKILL:core/dag-workflow:END -->

<!-- RULEBOOK:SKILL:core/documentation-rules:START -->
# Documentation Standards

**CRITICAL**: All documentation in English. Root README concise, detailed docs in `/docs`.

## Structure

**Root-Level (ONLY):**
- `README.md` - Overview + quick start
- `CHANGELOG.md` - Version history
- `AGENTS.md` - AI instructions
- `LICENSE`, `CONTRIBUTING.md`, `SECURITY.md`

**All Other Docs in `/docs`:**
- `ARCHITECTURE.md`, `DEVELOPMENT.md`, `ROADMAP.md`
- `specs/`, `guides/`, `diagrams/`, `benchmarks/`

## Update Requirements by Commit Type

| Type | Update |
|------|--------|
| `feat` | README features, API docs, CHANGELOG "Added" |
| `fix` | Troubleshooting, CHANGELOG "Fixed" |
| `breaking` | CHANGELOG + migration guide, version docs |
| `perf` | Benchmarks, CHANGELOG "Performance" |
| `security` | SECURITY.md, CHANGELOG "Security" |
| `docs` | Verify spelling/links only |
| `refactor` | Update if behavior changed |

## Quality Checks (CI/CD)

```bash
markdownlint **/*.md         # Lint markdown
markdown-link-check **/*.md  # Check links
codespell **/*.md            # Spell check
```

**MUST pass before commit** (see AGENT_AUTOMATION).
<!-- RULEBOOK:SKILL:core/documentation-rules:END -->

<!-- RULEBOOK:SKILL:core/quality-enforcement:START -->
<!-- QUALITY_ENFORCEMENT:START -->
# Quality Enforcement Rules

**CRITICAL**: These rules are NON-NEGOTIABLE and MUST be followed without exception.

## Absolute Prohibitions

### Test Bypassing - STRICTLY FORBIDDEN
- NEVER use .skip(), .only(), or .todo() to bypass failing tests
- NEVER comment out failing tests
- NEVER use @ts-ignore, @ts-expect-error, or similar to hide test errors
- NEVER mock/stub functionality just to make tests pass without fixing root cause
- FIX the actual problem causing test failures

### Git Hook Bypassing - STRICTLY FORBIDDEN  
- NEVER use --no-verify flag on git commit
- NEVER use --no-verify flag on git push
- NEVER disable or skip pre-commit hooks
- NEVER disable or skip pre-push hooks
- FIX the issues that hooks are detecting

### Test Implementation - STRICTLY FORBIDDEN
- NEVER create boilerplate tests that don't actually test behavior
- NEVER write tests that always pass regardless of implementation
- NEVER write tests without assertions
- NEVER mock everything to avoid testing real behavior
- WRITE meaningful tests that verify actual functionality

### Problem Solving Approach - REQUIRED
- DO NOT seek the simplest bypass or workaround
- DO NOT be creative with shortcuts that compromise quality
- DO solve problems properly following best practices
- DO use proven, established solutions from decades of experience
- DO fix root causes, not symptoms

### Temporary Files and Scripts - STRICTLY FORBIDDEN
- **NEVER** create temporary files in project root or any directory outside `/scripts`
- **NEVER** create test files, log files, or debug files outside `/scripts`
- **NEVER** leave temporary files after use - they MUST be deleted immediately
- **ALWAYS** create all scripts inside `/scripts` directory
- **ALWAYS** remove temporary files immediately after use (MANDATORY)
- **ALWAYS** clean up test artifacts, log files, and debug files before committing
- **ALWAYS** use `/scripts` directory for any temporary scripts or test files

**Why This Matters:**
LLM assistants often create temporary files for testing but forget to remove them, accumulating dozens of junk files that pollute the repository. All temporary work MUST be done in `/scripts` and cleaned up immediately.

**Examples:**
- ‚ùå Creating `test.js`, `debug.log`, `temp.json` in project root
- ‚ùå Leaving test files after debugging
- ‚ùå Creating scripts outside `/scripts` directory
- ‚úÖ Creating `/scripts/test-feature.js` and removing it after use
- ‚úÖ Using `/scripts` for all temporary work
- ‚úÖ Cleaning up all temporary files before committing

## Enforcement

These rules apply to ALL implementations:
- Bug fixes
- New features  
- Refactoring
- Documentation changes
- Any code modifications

**Violation = Implementation Rejected**

<!-- QUALITY_ENFORCEMENT:END -->


<!-- RULEBOOK:SKILL:core/quality-enforcement:END -->

<!-- RULEBOOK:SKILL:core/rulebook-task-management:START -->
# Rulebook Task Management

**CRITICAL**: Use Rulebook's built-in task management system for spec-driven development of new features and breaking changes.

## When to Use

Create tasks for:
- New features/capabilities
- Breaking changes
- Architecture changes
- Performance/security work

Skip for:
- Bug fixes (restore intended behavior)
- Typos, formatting, comments
- Dependency updates (non-breaking)

## Task Creation is MANDATORY Before Implementation

**ABSOLUTE RULE**: You MUST create a task BEFORE implementing ANY feature.

### MANDATORY Workflow

**NEVER start implementation without creating a task first:**

```bash
# WRONG: Starting implementation directly
# ... writing code without task ...

# CORRECT: Create task first
rulebook task create <task-id>
# Write proposal.md
# Write tasks.md
# Write spec deltas
rulebook task validate <task-id>
# NOW you can start implementation
```

### Task Creation Steps

**When a feature is requested:**

1. **STOP** - Do not start coding
2. **Create task** - `rulebook task create <task-id>`
3. **Plan** - Write proposal.md and tasks.md
4. **Spec** - Write spec deltas
5. **Validate** - `rulebook task validate <task-id>`
6. **THEN** - Start implementation

## Task Directory Structure

```
.rulebook/tasks/<task-id>/
‚îú‚îÄ‚îÄ proposal.md         # Why and what changes
‚îú‚îÄ‚îÄ tasks.md            # Implementation checklist
‚îú‚îÄ‚îÄ design.md           # Technical design (optional)
‚îî‚îÄ‚îÄ specs/
    ‚îî‚îÄ‚îÄ <module>/
        ‚îî‚îÄ‚îÄ spec.md     # Technical specifications
```

## Task Commands

```bash
# Create new task
rulebook task create <task-id>

# List all tasks
rulebook task list

# Show task details
rulebook task show <task-id>

# Validate task structure
rulebook task validate <task-id>

# Archive completed task
rulebook task archive <task-id>
```

## Proposal Format (proposal.md)

```markdown
# Proposal: <Task Title>

## Why
<Explain the problem or opportunity>

## What Changes
<List of changes with ADDED/MODIFIED/REMOVED markers>

## Impact
- Affected specs: <list spec files>
- Affected code: <list source files>
- Breaking change: YES/NO
- User benefit: <describe benefit>
```

## Tasks Format (tasks.md)

**CRITICAL**: Only simple checklist items. Technical details go in specs.

```markdown
## 1. <Phase Name>
- [ ] 1.1 <Simple task description>
- [ ] 1.2 <Simple task description>

## 2. <Phase Name>
- [ ] 2.1 <Simple task description>
```

## Spec Delta Format (specs/<module>/spec.md)

```markdown
# <Module> Specification

## ADDED Requirements

### Requirement: <Name>
<Description>

#### Scenario: <Name>
Given <context>
When <action>
Then <expected result>

## MODIFIED Requirements

### Requirement: <Original Name>
<Description of modification>

## REMOVED Requirements

### Requirement: <Name to Remove>
<Reason for removal>
```

## MCP Integration

If MCP server is enabled, use programmatic task management:

```typescript
// Create task
await mcp.rulebook_task_create({ taskId: "my-task" });

// List tasks
await mcp.rulebook_task_list({});

// Show task
await mcp.rulebook_task_show({ taskId: "my-task" });

// Validate task
await mcp.rulebook_task_validate({ taskId: "my-task" });

// Archive task
await mcp.rulebook_task_archive({ taskId: "my-task" });
```

## Best Practices

1. **Always create task first** - Never implement without documentation
2. **Keep tasks.md simple** - Only checklist items, no explanations
3. **Put details in specs** - Technical requirements go in spec files
4. **Validate before implementing** - Run `rulebook task validate`
5. **Archive when done** - Move completed tasks to archive

<!-- RULEBOOK:SKILL:core/rulebook-task-management:END -->

<!-- RULEBOOK:SKILL:languages/c:START -->
<!-- C:START -->
# C Project Rules

## Agent Automation Commands

**CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow).

```bash
# Complete quality check sequence:
clang-format --dry-run --Werror src/**/*.c  # Format check
make lint                 # Linting (if configured)
make test                 # All tests (100% pass)
make                      # Build verification

# Memory safety (recommended):
valgrind --leak-check=full ./build/test  # Memory leak check
```

## C Configuration

**CRITICAL**: Use C11 or C17 standard with strict warnings enabled.

- **Standard**: C11 or C17
- **Compiler**: GCC 11+ or Clang 14+
- **Build System**: CMake 3.20+ (recommended) or Make
- **Warnings**: Treat all warnings as errors
- **Sanitizers**: ASAN, UBSAN for memory safety

### CMakeLists.txt Requirements

```cmake
cmake_minimum_required(VERSION 3.20)
project(YourProject C)

set(CMAKE_C_STANDARD 17)
set(CMAKE_C_STANDARD_REQUIRED ON)
set(CMAKE_C_EXTENSIONS OFF)

# Compiler warnings
if(MSVC)
  add_compile_options(/W4 /WX)
else()
  add_compile_options(-Wall -Wextra -Werror -pedantic)
endif()

# Enable sanitizers in Debug mode
if(CMAKE_BUILD_TYPE STREQUAL "Debug")
  add_compile_options(-fsanitize=address,undefined)
  add_link_options(-fsanitize=address,undefined)
endif()

# Source files
add_executable(${PROJECT_NAME} src/main.c src/module.c)

# Include directories
target_include_directories(${PROJECT_NAME} PUBLIC include)

# Enable testing
enable_testing()
add_subdirectory(tests)
```

## Code Quality Standards

### Mandatory Quality Checks

**CRITICAL**: After implementing ANY feature, you MUST run these commands in order.

**IMPORTANT**: These commands MUST match your GitHub Actions workflows to prevent CI/CD failures!

```bash
# Pre-Commit Checklist (MUST match .github/workflows/*.yml)

# 1. Format check (matches workflow - use --dry-run, not -i!)
clang-format --dry-run --Werror src/**/*.c include/**/*.h tests/**/*.c

# 2. Static analysis (matches workflow)
clang-tidy src/**/*.c -- -std=c17 -Wall -Wextra -Werror

# 3. Build with warnings as errors (matches workflow)
cmake -B build -DCMAKE_BUILD_TYPE=Release -DCMAKE_C_FLAGS="-Werror -Wall -Wextra -pedantic"
cmake --build build

# 4. Run all tests (MUST pass 100% - matches workflow)
ctest --test-dir build --output-on-failure --verbose

# 5. Check with Address Sanitizer (matches workflow)
cmake -B build-asan -DCMAKE_BUILD_TYPE=Debug \
  -DCMAKE_C_FLAGS="-fsanitize=address,undefined -g"
cmake --build build-asan
ctest --test-dir build-asan --output-on-failure

# 6. Check with Valgrind (matches workflow)
valgrind --leak-check=full --error-exitcode=1 ./build/YourProject

# 7. Check coverage (matches workflow)
cmake -B build-cov -DCMAKE_BUILD_TYPE=Coverage \
  -DCMAKE_C_FLAGS="-fprofile-arcs -ftest-coverage"
cmake --build build-cov
ctest --test-dir build-cov
gcov build-cov/CMakeFiles/YourProject.dir/src/*.gcno
lcov --capture --directory build-cov --output-file coverage.info
lcov --list coverage.info

# If ANY fails: ‚ùå DO NOT COMMIT - Fix first!
```

**If ANY of these fail, you MUST fix the issues before committing.**

**Why This Matters:**
- Running different commands locally than in CI causes "works on my machine" failures
- CI/CD failures happen when local checks differ from workflows
- Example: Using `clang-format -i` locally but `--dry-run --Werror` in CI = failure
- Example: Missing `-Werror` flag = warnings pass locally but fail in CI
- Example: Skipping sanitizers locally = CI catches memory bugs, use-after-free, buffer overflows
- Example: Not running Valgrind = memory leaks pass locally but fail in CI

### Formatting

- Use clang-format for consistent code style
- Configuration in `.clang-format`
- Check formatting in CI (don't auto-format)

Example `.clang-format`:
```yaml
Language: C
BasedOnStyle: LLVM
IndentWidth: 4
ColumnLimit: 100
AllowShortFunctionsOnASingleLine: Empty
BreakBeforeBraces: Attach
AlignConsecutiveMacros: true
```

### Static Analysis

- Use clang-tidy for static analysis
- Configuration in `.clang-tidy`
- Enable modernize and bugprone checks

Example `.clang-tidy`:
```yaml
Checks: >
  -*,
  bugprone-*,
  clang-analyzer-*,
  modernize-*,
  readability-*,
  performance-*,
  portability-*

CheckOptions:
  - key: readability-identifier-naming.FunctionCase
    value: lower_case
  - key: readability-identifier-naming.VariableCase
    value: lower_case
```

### Testing

- **Framework**: Unity, Check, or CTest
- **Location**: `/tests` directory
- **Coverage**: Must meet threshold (80%+)
- **Sanitizers**: ASAN, UBSAN, Valgrind
- **Memory Safety**: Zero memory leaks

Example Unity test:
```c
#include "unity.h"
#include "module.h"

void setUp(void) {
    // Setup before each test
}

void tearDown(void) {
    // Cleanup after each test
}

void test_function_should_return_expected_value(void) {
    int result = my_function(10);
    TEST_ASSERT_EQUAL_INT(20, result);
}

void test_function_should_handle_null_pointer(void) {
    TEST_ASSERT_NULL(my_function_with_null(NULL));
}

int main(void) {
    UNITY_BEGIN();
    RUN_TEST(test_function_should_return_expected_value);
    RUN_TEST(test_function_should_handle_null_pointer);
    return UNITY_END();
}
```

## Memory Safety

**CRITICAL**: Always check for memory issues.

### Required Checks

1. **Address Sanitizer (ASAN)**:
   ```bash
   gcc -fsanitize=address -g -o program main.c
   ./program
   ```

2. **Undefined Behavior Sanitizer (UBSAN)**:
   ```bash
   gcc -fsanitize=undefined -g -o program main.c
   ./program
   ```

3. **Valgrind**:
   ```bash
   valgrind --leak-check=full --show-leak-kinds=all ./program
   ```

4. **Static Analysis**:
   ```bash
   clang-tidy src/**/*.c
   cppcheck --enable=all --error-exitcode=1 src/
   ```

### Common Memory Issues to Prevent

```c
// ‚ùå BAD: Memory leak
char *buffer = malloc(100);
// ... use buffer ...
// Missing free()

// ‚úÖ GOOD: Proper cleanup
char *buffer = malloc(100);
if (buffer == NULL) {
    return ERROR_NO_MEMORY;
}
// ... use buffer ...
free(buffer);
buffer = NULL;

// ‚ùå BAD: Use after free
char *ptr = malloc(10);
free(ptr);
strcpy(ptr, "test");  // UNDEFINED BEHAVIOR!

// ‚úÖ GOOD: NULL after free
char *ptr = malloc(10);
free(ptr);
ptr = NULL;
if (ptr != NULL) {
    strcpy(ptr, "test");
}

// ‚ùå BAD: Buffer overflow
char buffer[10];
strcpy(buffer, "This is too long");  // BUFFER OVERFLOW!

// ‚úÖ GOOD: Bounds checking
char buffer[10];
strncpy(buffer, "Safe", sizeof(buffer) - 1);
buffer[sizeof(buffer) - 1] = '\0';
```

## Best Practices

### DO's ‚úÖ

- **CHECK** return values from all functions
- **VALIDATE** all pointer arguments for NULL
- **FREE** all allocated memory
- **USE** const for immutable pointers
- **LIMIT** variable scope
- **ZERO** memory after free for security
- **BOUNDS** check all array accesses
- **SANITIZE** all inputs

### DON'Ts ‚ùå

- **NEVER** ignore compiler warnings
- **NEVER** assume malloc succeeds
- **NEVER** use gets() (use fgets())
- **NEVER** use strcpy() (use strncpy() or strlcpy())
- **NEVER** use sprintf() (use snprintf())
- **NEVER** dereference NULL pointers
- **NEVER** return pointers to stack variables
- **NEVER** skip sanitizer checks

## Security Guidelines

1. **Input Validation**: Validate all external inputs
2. **Buffer Safety**: Always check bounds
3. **Integer Overflow**: Check arithmetic operations
4. **Format String**: Never use user input as format string
5. **Memory Zeroization**: Zero sensitive data after use

Example secure code:
```c
#include <string.h>
#include <stdlib.h>
#include <stdio.h>

// Secure string copy with bounds checking
int safe_strcpy(char *dest, size_t dest_size, const char *src) {
    if (dest == NULL || src == NULL || dest_size == 0) {
        return -1;
    }
    
    size_t src_len = strlen(src);
    if (src_len >= dest_size) {
        return -1;  // Not enough space
    }
    
    strncpy(dest, src, dest_size - 1);
    dest[dest_size - 1] = '\0';
    return 0;
}

// Secure memory cleanup
void secure_free(void **ptr, size_t size) {
    if (ptr == NULL || *ptr == NULL) {
        return;
    }
    
    // Zero memory before free
    memset(*ptr, 0, size);
    free(*ptr);
    *ptr = NULL;
}
```

<!-- C:END -->

<!-- RULEBOOK:SKILL:languages/c:END -->

<!-- RULEBOOK:SKILL:languages/c:START -->
<!-- CPP:START -->
# C/C++ Project Rules

## Agent Automation Commands

**CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow).

```bash
# Complete quality check sequence:
clang-format --dry-run --Werror src/**/*.cpp  # Format check
clang-tidy src/**/*.cpp   # Linting
make test                 # All tests (100% pass)
make                      # Build verification

# Additional checks:
cppcheck --enable=all src/  # Static analysis
valgrind --leak-check=full ./build/test  # Memory check
```

## C/C++ Configuration

**CRITICAL**: Use C++20 or C++23 with modern CMake.

- **C++ Standard**: C++20 or C++23
- **CMake**: 3.25+
- **Compiler**: GCC 11+, Clang 15+, or MSVC 19.30+
- **Build System**: CMake (recommended) or Meson
- **Package Manager**: Conan or vcpkg

### CMakeLists.txt Requirements

```cmake
cmake_minimum_required(VERSION 3.25)
project(YourProject VERSION 1.0.0 LANGUAGES CXX)

# C++ Standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Compiler warnings
if(MSVC)
    add_compile_options(/W4 /WX)
else()
    add_compile_options(-Wall -Wextra -Wpedantic -Werror)
endif()

# Export compile commands for tooling
set(CMAKE_EXPORT_COMPILE_COMMANDS ON)

# Project options
option(BUILD_TESTING "Build tests" ON)
option(BUILD_DOCS "Build documentation" ON)
option(ENABLE_SANITIZERS "Enable sanitizers" ON)

# Dependencies (using FetchContent or find_package)
include(FetchContent)

FetchContent_Declare(
    googletest
    GIT_REPOSITORY https://github.com/google/googletest.git
    GIT_TAG v1.14.0
)
FetchContent_MakeAvailable(googletest)

# Library
add_library(${PROJECT_NAME}
    src/your_module.cpp
    src/your_module.hpp
)

target_include_directories(${PROJECT_NAME}
    PUBLIC
        $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>
        $<INSTALL_INTERFACE:include>
    PRIVATE
        ${CMAKE_CURRENT_SOURCE_DIR}/src
)

# Enable sanitizers in debug
if(ENABLE_SANITIZERS AND CMAKE_BUILD_TYPE MATCHES Debug)
    target_compile_options(${PROJECT_NAME} PRIVATE
        -fsanitize=address
        -fsanitize=undefined
        -fno-omit-frame-pointer
    )
    target_link_options(${PROJECT_NAME} PRIVATE
        -fsanitize=address
        -fsanitize=undefined
    )
endif()

# Tests
if(BUILD_TESTING)
    enable_testing()
    add_subdirectory(tests)
endif()

# Installation
install(TARGETS ${PROJECT_NAME}
    EXPORT ${PROJECT_NAME}Targets
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
    RUNTIME DESTINATION bin
    INCLUDES DESTINATION include
)
```

## Code Quality Standards

### Mandatory Quality Checks

**CRITICAL**: After implementing ANY feature, you MUST run these commands in order.

**IMPORTANT**: These commands MUST match your GitHub Actions workflows to prevent CI/CD failures!

```bash
# Pre-Commit Checklist (MUST match .github/workflows/*.yml)

# 1. Format check (matches workflow - use --dry-run, not -i!)
clang-format --dry-run --Werror src/**/*.{cpp,hpp} tests/**/*.{cpp,hpp}

# 2. Static analysis (matches workflow)
clang-tidy src/**/*.cpp -- -std=c++20

# 3. Build (MUST pass with no warnings - matches workflow)
cmake -B build -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="-Werror"
cmake --build build

# 4. Run all tests (MUST pass 100% - matches workflow)
ctest --test-dir build --output-on-failure

# 5. Check with sanitizers (matches workflow)
cmake -B build-asan -DENABLE_SANITIZERS=ON
cmake --build build-asan
ctest --test-dir build-asan

# 6. Check coverage (matches workflow)
cmake -B build-cov -DCMAKE_BUILD_TYPE=Coverage
cmake --build build-cov
ctest --test-dir build-cov
gcov build-cov/CMakeFiles/YourProject.dir/src/*.gcno

# If ANY fails: ‚ùå DO NOT COMMIT - Fix first!
```

**Why This Matters:**
- CI/CD failures happen when local commands differ from workflows
- Example: Using `clang-format -i` locally but `--dry-run --Werror` in CI = failure
- Example: Missing `-Werror` flag = warnings pass locally but fail in CI
- Example: Skipping sanitizers locally = CI catches memory bugs you missed
```

**If ANY of these fail, you MUST fix the issues before committing.**

### Code Style

Use `.clang-format` for consistent formatting:

```yaml
---
Language: Cpp
BasedOnStyle: Google
IndentWidth: 4
ColumnLimit: 100
UseTab: Never
PointerAlignment: Left
ReferenceAlignment: Left
DerivePointerAlignment: false

# Includes
SortIncludes: CaseInsensitive
IncludeBlocks: Regroup
IncludeCategories:
  - Regex: '^<.*\.h>'
    Priority: 1
  - Regex: '^<.*>'
    Priority: 2
  - Regex: '.*'
    Priority: 3

# Braces
BreakBeforeBraces: Attach
AllowShortFunctionsOnASingleLine: Inline
AllowShortIfStatementsOnASingleLine: Never

# Spacing
SpaceAfterCStyleCast: false
SpaceAfterTemplateKeyword: true
SpaceBeforeParens: ControlStatements

# Modern C++
Standard: c++20
```

### Static Analysis

Use `.clang-tidy` for code analysis:

```yaml
---
Checks: >
  *,
  -abseil-*,
  -altera-*,
  -android-*,
  -fuchsia-*,
  -google-*,
  -llvm-*,
  -llvmlibc-*,
  -zircon-*,
  -readability-identifier-length,
  -modernize-use-trailing-return-type

CheckOptions:
  - key: readability-identifier-naming.NamespaceCase
    value: lower_case
  - key: readability-identifier-naming.ClassCase
    value: CamelCase
  - key: readability-identifier-naming.StructCase
    value: CamelCase
  - key: readability-identifier-naming.FunctionCase
    value: camelCase
  - key: readability-identifier-naming.VariableCase
    value: lower_case
  - key: readability-identifier-naming.ConstantCase
    value: UPPER_CASE
  - key: readability-identifier-naming.MemberCase
    value: lower_case_
  - key: readability-identifier-naming.PrivateMemberSuffix
    value: '_'

WarningsAsErrors: '*'
```

### Testing

- **Framework**: Google Test (recommended) or Catch2
- **Location**: `tests/` directory
- **Coverage**: gcov/lcov or llvm-cov
- **Coverage Threshold**: 95%+

Example test with Google Test:

```cpp
#include <gtest/gtest.h>
#include "your_module.hpp"

namespace your_namespace::tests {

class DataProcessorTest : public ::testing::Test {
protected:
    void SetUp() override {
        processor = std::make_unique<DataProcessor>();
    }

    void TearDown() override {
        processor.reset();
    }

    std::unique_ptr<DataProcessor> processor;
};

TEST_F(DataProcessorTest, ProcessValidInput) {
    const std::string input = "hello";
    const auto result = processor->process(input);
    
    EXPECT_EQ(result, "HELLO");
}

TEST_F(DataProcessorTest, ProcessEmptyInputThrows) {
    EXPECT_THROW(
        processor->process(""),
        std::invalid_argument
    );
}

TEST_F(DataProcessorTest, ProcessLargeInput) {
    const std::string input(1000, 'a');
    const auto result = processor->process(input);
    
    ASSERT_EQ(result.size(), 1000);
    EXPECT_TRUE(std::all_of(result.begin(), result.end(), 
        [](char c) { return std::isupper(c); }));
}

} // namespace your_namespace::tests
```

### Modern C++ Best Practices

- Use RAII for resource management
- Prefer `std::unique_ptr` and `std::shared_ptr` over raw pointers
- Use `const` and `constexpr` liberally
- Prefer `std::string_view` for read-only strings
- Use range-based for loops
- Use `auto` for type deduction when clear
- Avoid manual memory management

Example modern C++ code:

```cpp
#pragma once

#include <memory>
#include <string>
#include <string_view>
#include <vector>
#include <optional>
#include <expected>

namespace your_namespace {

/// @brief Processes data with various transformations
class DataProcessor {
public:
    DataProcessor() = default;
    ~DataProcessor() = default;
    
    // Delete copy constructor and assignment
    DataProcessor(const DataProcessor&) = delete;
    DataProcessor& operator=(const DataProcessor&) = delete;
    
    // Default move constructor and assignment
    DataProcessor(DataProcessor&&) noexcept = default;
    DataProcessor& operator=(DataProcessor&&) noexcept = default;
    
    /// @brief Process input string to uppercase
    /// @param input The input string to process
    /// @return Processed string or error
    /// @throws std::invalid_argument if input is empty
    [[nodiscard]] std::string process(std::string_view input) const;
    
    /// @brief Find value in data
    /// @param data The data to search
    /// @param key The key to find
    /// @return Optional value if found
    [[nodiscard]] std::optional<std::string> findValue(
        const std::vector<std::pair<std::string, std::string>>& data,
        std::string_view key
    ) const;
    
    /// @brief Process multiple items
    /// @param items Items to process
    /// @return Processed items
    [[nodiscard]] std::vector<std::string> processMany(
        const std::vector<std::string>& items
    ) const;

private:
    mutable std::mutex mutex_;
};

} // namespace your_namespace
```

Implementation:

```cpp
#include "your_module.hpp"
#include <algorithm>
#include <stdexcept>
#include <cctype>

namespace your_namespace {

std::string DataProcessor::process(std::string_view input) const {
    if (input.empty()) {
        throw std::invalid_argument("Input cannot be empty");
    }
    
    std::string result;
    result.reserve(input.size());
    
    std::transform(input.begin(), input.end(), 
                   std::back_inserter(result),
                   [](unsigned char c) { return std::toupper(c); });
    
    return result;
}

std::optional<std::string> DataProcessor::findValue(
    const std::vector<std::pair<std::string, std::string>>& data,
    std::string_view key
) const {
    auto it = std::find_if(data.begin(), data.end(),
        [key](const auto& pair) { return pair.first == key; });
    
    if (it != data.end()) {
        return it->second;
    }
    
    return std::nullopt;
}

std::vector<std::string> DataProcessor::processMany(
    const std::vector<std::string>& items
) const {
    std::vector<std::string> results;
    results.reserve(items.size());
    
    std::transform(items.begin(), items.end(),
                   std::back_inserter(results),
                   [this](const auto& item) { return process(item); });
    
    return results;
}

} // namespace your_namespace
```

## Documentation

Use Doxygen for API documentation:

```cpp
/**
 * @file your_module.hpp
 * @brief Data processing utilities
 * @author Your Name
 * @date 2024-10-23
 */

/**
 * @class DataProcessor
 * @brief Processes various data formats
 * 
 * This class provides thread-safe data processing capabilities.
 * All methods are const-correct and exception-safe.
 * 
 * @example
 * @code{.cpp}
 * DataProcessor processor;
 * auto result = processor.process("hello");
 * assert(result == "HELLO");
 * @endcode
 */
```

### Doxyfile Configuration:

```
PROJECT_NAME = "Your Project"
PROJECT_NUMBER = 1.0.0
OUTPUT_DIRECTORY = docs
GENERATE_HTML = YES
GENERATE_LATEX = NO
EXTRACT_ALL = YES
EXTRACT_PRIVATE = NO
EXTRACT_STATIC = YES
SOURCE_BROWSER = YES
INLINE_SOURCES = YES
RECURSIVE = YES
```

## Project Structure

```
project/
‚îú‚îÄ‚îÄ CMakeLists.txt          # CMake configuration
‚îú‚îÄ‚îÄ .clang-format           # Code formatting rules
‚îú‚îÄ‚îÄ .clang-tidy             # Static analysis rules
‚îú‚îÄ‚îÄ Doxyfile                # Documentation config
‚îú‚îÄ‚îÄ conanfile.txt           # Conan dependencies (optional)
‚îú‚îÄ‚îÄ vcpkg.json              # vcpkg dependencies (optional)
‚îú‚îÄ‚îÄ README.md               # Project overview
‚îú‚îÄ‚îÄ CHANGELOG.md            # Version history
‚îú‚îÄ‚îÄ LICENSE                 # Project license
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îî‚îÄ‚îÄ your_project/
‚îÇ       ‚îî‚îÄ‚îÄ your_module.hpp # Public headers
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ your_module.cpp     # Implementation
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ CMakeLists.txt
‚îÇ   ‚îî‚îÄ‚îÄ test_your_module.cpp
‚îú‚îÄ‚îÄ benchmarks/             # Performance benchmarks
‚îÇ   ‚îî‚îÄ‚îÄ benchmark_main.cpp
‚îî‚îÄ‚îÄ docs/                   # Project documentation
```

## Memory Safety

- Use RAII for all resource management
- Prefer stack allocation over heap
- Use smart pointers for heap allocation
- Never use raw `new`/`delete`
- Use containers instead of manual arrays
- Check all pointer dereferences

Example:

```cpp
// Good: RAII with smart pointers
class FileManager {
public:
    explicit FileManager(std::string_view filename) 
        : file_(std::make_unique<std::ifstream>(filename.data())) {
        if (!file_->is_open()) {
            throw std::runtime_error("Failed to open file");
        }
    }
    
    // RAII - file automatically closed
    ~FileManager() = default;
    
    [[nodiscard]] std::string readLine() {
        std::string line;
        if (std::getline(*file_, line)) {
            return line;
        }
        throw std::runtime_error("Failed to read line");
    }

private:
    std::unique_ptr<std::ifstream> file_;
};

// Bad: Manual memory management
class BadFileManager {
public:
    BadFileManager(const char* filename) {
        file = new std::ifstream(filename);  // ‚ùå Manual allocation
    }
    
    ~BadFileManager() {
        delete file;  // ‚ùå Manual deletion (error-prone)
    }

private:
    std::ifstream* file;  // ‚ùå Raw pointer
};
```

## Error Handling

- Use exceptions for exceptional cases
- Use `std::expected` (C++23) or `std::optional` for expected failures
- Create custom exception classes
- Document all exceptions with `@throws`

Example:

```cpp
#include <stdexcept>
#include <optional>

namespace your_namespace {

class ValidationError : public std::runtime_error {
public:
    explicit ValidationError(std::string_view message, std::string_view field)
        : std::runtime_error(std::string(message))
        , field_(field) {}
    
    [[nodiscard]] const std::string& field() const noexcept { return field_; }

private:
    std::string field_;
};

class DataValidator {
public:
    /// @throws ValidationError if data is invalid
    void validate(std::string_view data) const {
        if (data.empty()) {
            throw ValidationError("Data cannot be empty", "data");
        }
    }
    
    /// @return Optional value if valid, nullopt otherwise
    [[nodiscard]] std::optional<int> tryParse(std::string_view str) const noexcept {
        try {
            return std::stoi(std::string(str));
        } catch (...) {
            return std::nullopt;
        }
    }
};

} // namespace your_namespace
```

## Threading & Concurrency

- Use `std::thread`, `std::jthread` (C++20), or `std::async`
- Use `std::mutex`, `std::shared_mutex` for synchronization
- Prefer `std::atomic` for simple shared state
- Use `std::lock_guard` or `std::scoped_lock`

Example:

```cpp
#include <mutex>
#include <shared_mutex>
#include <thread>
#include <atomic>

class ThreadSafeCounter {
public:
    void increment() {
        std::scoped_lock lock(mutex_);
        ++counter_;
    }
    
    [[nodiscard]] int get() const {
        std::shared_lock lock(mutex_);
        return counter_;
    }

private:
    mutable std::shared_mutex mutex_;
    int counter_{0};
};

// For simple atomics
class AtomicCounter {
public:
    void increment() noexcept {
        counter_.fetch_add(1, std::memory_order_relaxed);
    }
    
    [[nodiscard]] int get() const noexcept {
        return counter_.load(std::memory_order_relaxed);
    }

private:
    std::atomic<int> counter_{0};
};
```

## CI/CD Requirements

Must include GitHub Actions workflows for:

1. **Testing** (`cpp-test.yml`):
   - Test on ubuntu-latest, windows-latest, macos-latest
   - Test with GCC, Clang, MSVC
   - Upload coverage reports

2. **Linting** (`cpp-lint.yml`):
   - clang-format check
   - clang-tidy analysis
   - cppcheck static analysis

## Package Publication

### Publishing C/C++ Libraries

**Options:**
1. **Conan Center**: Public Conan repository
2. **vcpkg**: Microsoft's package manager
3. **GitHub Releases**: Binary releases
4. **Header-only**: Single-file distribution

### Conan Publication

**conanfile.py:**

```python
from conan import ConanFile
from conan.tools.cmake import CMakeToolchain, CMake, cmake_layout

class YourProjectConan(ConanFile):
    name = "your-project"
    version = "1.0.0"
    license = "MIT"
    author = "Your Name your.email@example.com"
    url = "https://github.com/your-org/your-project"
    description = "Short description"
    topics = ("cpp", "library")
    settings = "os", "compiler", "build_type", "arch"
    
    options = {
        "shared": [True, False],
        "fPIC": [True, False]
    }
    default_options = {
        "shared": False,
        "fPIC": True
    }
    
    exports_sources = "CMakeLists.txt", "src/*", "include/*"
    
    def layout(self):
        cmake_layout(self)
    
    def generate(self):
        tc = CMakeToolchain(self)
        tc.generate()
    
    def build(self):
        cmake = CMake(self)
        cmake.configure()
        cmake.build()
    
    def package(self):
        cmake = CMake(self)
        cmake.install()
    
    def package_info(self):
        self.cpp_info.libs = ["your-project"]
```

### vcpkg Publication

**vcpkg.json:**

```json
{
  "name": "your-project",
  "version": "1.0.0",
  "description": "Short description",
  "homepage": "https://github.com/your-org/your-project",
  "license": "MIT",
  "dependencies": [
    {
      "name": "vcpkg-cmake",
      "host": true
    },
    {
      "name": "vcpkg-cmake-config",
      "host": true
    }
  ]
}
```

### Publishing Checklist:

- ‚úÖ All tests passing with sanitizers
- ‚úÖ clang-tidy clean
- ‚úÖ clang-format applied
- ‚úÖ Documentation generated
- ‚úÖ Version updated in CMakeLists.txt
- ‚úÖ CHANGELOG.md updated
- ‚úÖ README.md with build instructions
- ‚úÖ LICENSE file present
- ‚úÖ CMake config for find_package support
- ‚úÖ Conan recipe or vcpkg portfile

<!-- CPP:END -->


<!-- RULEBOOK:SKILL:languages/c:END -->

<!-- RULEBOOK:SKILL:languages/c:START -->
<!-- CSHARP:START -->
# C# Project Rules

## Agent Automation Commands

**CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow).

```bash
# Complete quality check sequence:
dotnet format --verify-no-changes  # Format check
dotnet build              # Build + compile check
dotnet test               # All tests (100% pass)
dotnet test --collect:"XPlat Code Coverage"  # Coverage (95%+ required)

# Security audit:
dotnet list package --vulnerable  # Vulnerability scan
dotnet list package --outdated    # Check outdated deps
```

## C# Configuration

**CRITICAL**: Use .NET 8+ with C# 12+.

- **Version**: .NET 8.0+
- **C# Version**: 12+
- **Target**: net8.0
- **Nullable**: Enabled
- **LangVersion**: latest

### Project File Requirements

```xml
<Project Sdk="Microsoft.NET.Sdk">
  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <LangVersion>latest</LangVersion>
    <Nullable>enable</Nullable>
    <ImplicitUsings>enable</ImplicitUsings>
    <TreatWarningsAsErrors>true</TreatWarningsAsErrors>
    <AnalysisMode>All</AnalysisMode>
    <EnforceCodeStyleInBuild>true</EnforceCodeStyleInBuild>
    
    <!-- Package Metadata -->
    <PackageId>Your.Package.Name</PackageId>
    <Version>1.0.0</Version>
    <Authors>Your Name</Authors>
    <Company>Your Company</Company>
    <Description>A short description of your package</Description>
    <PackageLicenseExpression>MIT</PackageLicenseExpression>
    <PackageProjectUrl>https://github.com/your-org/your-project</PackageProjectUrl>
    <RepositoryUrl>https://github.com/your-org/your-project</RepositoryUrl>
    <RepositoryType>git</RepositoryType>
    <PackageTags>your;tags</PackageTags>
    
    <!-- Documentation -->
    <GenerateDocumentationFile>true</GenerateDocumentationFile>
    <NoWarn>$(NoWarn);1591</NoWarn>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.CodeAnalysis.NetAnalyzers" Version="8.0.0">
      <PrivateAssets>all</PrivateAssets>
      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>
    </PackageReference>
  </ItemGroup>
</Project>
```

## Code Quality Standards

### Mandatory Quality Checks

**CRITICAL**: After implementing ANY feature, you MUST run these commands in order.

**IMPORTANT**: These commands MUST match your GitHub Actions workflows to prevent CI/CD failures!

```bash
# Pre-Commit Checklist (MUST match .github/workflows/*.yml)

# 1. Format check (matches workflow - use --verify-no-changes!)
dotnet format --verify-no-changes

# 2. Build (MUST pass with no warnings - matches workflow)
dotnet build --no-incremental --warnaserror

# 3. Run all tests (MUST pass 100% - matches workflow)
dotnet test --no-build

# 4. Check coverage (MUST meet threshold)
dotnet test /p:CollectCoverage=true /p:CoverletOutputFormat=opencover

# If ANY fails: ‚ùå DO NOT COMMIT - Fix first!
```

**If ANY of these fail, you MUST fix the issues before committing.**

**Why This Matters:**
- CI/CD failures happen when local commands differ from workflows
- Example: Using `dotnet format` locally but `dotnet format --verify-no-changes` in CI = failure
- Example: Missing `--warnaserror` flag = warnings pass locally but fail in CI

### Code Style

Use `.editorconfig` for consistent code style:

```ini
root = true

[*]
charset = utf-8
indent_style = space
indent_size = 4
insert_final_newline = true
trim_trailing_whitespace = true

[*.{cs,csx,vb,vbx}]
indent_size = 4

# C# Code Style Rules
[*.cs]
# Organize usings
dotnet_sort_system_directives_first = true
dotnet_separate_import_directive_groups = false

# this. preferences
dotnet_style_qualification_for_field = false:warning
dotnet_style_qualification_for_property = false:warning
dotnet_style_qualification_for_method = false:warning
dotnet_style_qualification_for_event = false:warning

# Language keywords vs BCL types preferences
dotnet_style_predefined_type_for_locals_parameters_members = true:warning
dotnet_style_predefined_type_for_member_access = true:warning

# Modifier preferences
dotnet_style_require_accessibility_modifiers = always:warning
csharp_preferred_modifier_order = public,private,protected,internal,static,extern,new,virtual,abstract,sealed,override,readonly,unsafe,volatile,async:warning

# Expression preferences
csharp_style_var_for_built_in_types = true:warning
csharp_style_var_when_type_is_apparent = true:warning
csharp_style_var_elsewhere = true:warning

# Pattern matching
csharp_style_pattern_matching_over_is_with_cast_check = true:warning
csharp_style_pattern_matching_over_as_with_null_check = true:warning

# Null-checking preferences
csharp_style_throw_expression = true:warning
csharp_style_conditional_delegate_call = true:warning

# Code block preferences
csharp_prefer_braces = true:warning
csharp_prefer_simple_using_statement = true:warning

# Naming conventions
dotnet_naming_rule.interface_should_be_begins_with_i.severity = warning
dotnet_naming_rule.interface_should_be_begins_with_i.symbols = interface
dotnet_naming_rule.interface_should_be_begins_with_i.style = begins_with_i

dotnet_naming_rule.types_should_be_pascal_case.severity = warning
dotnet_naming_rule.types_should_be_pascal_case.symbols = types
dotnet_naming_rule.types_should_be_pascal_case.style = pascal_case

dotnet_naming_rule.non_field_members_should_be_pascal_case.severity = warning
dotnet_naming_rule.non_field_members_should_be_pascal_case.symbols = non_field_members
dotnet_naming_rule.non_field_members_should_be_pascal_case.style = pascal_case

# Symbol specifications
dotnet_naming_symbols.interface.applicable_kinds = interface
dotnet_naming_symbols.interface.applicable_accessibilities = public, internal, private, protected, protected_internal, private_protected

dotnet_naming_symbols.types.applicable_kinds = class, struct, interface, enum
dotnet_naming_symbols.types.applicable_accessibilities = public, internal, private, protected, protected_internal, private_protected

dotnet_naming_symbols.non_field_members.applicable_kinds = property, event, method
dotnet_naming_symbols.non_field_members.applicable_accessibilities = public, internal, private, protected, protected_internal, private_protected

# Naming styles
dotnet_naming_style.begins_with_i.required_prefix = I
dotnet_naming_style.begins_with_i.required_suffix = 
dotnet_naming_style.begins_with_i.word_separator = 
dotnet_naming_style.begins_with_i.capitalization = pascal_case

dotnet_naming_style.pascal_case.required_prefix = 
dotnet_naming_style.pascal_case.required_suffix = 
dotnet_naming_style.pascal_case.word_separator = 
dotnet_naming_style.pascal_case.capitalization = pascal_case
```

### Testing

- **Framework**: xUnit (recommended) or NUnit
- **Location**: Separate test project
- **Coverage**: Coverlet
- **Coverage Threshold**: 95%+

Example test structure:
```csharp
using Xunit;

namespace YourProject.Tests;

public class MyClassTests
{
    [Fact]
    public void Process_ValidInput_ReturnsExpectedResult()
    {
        // Arrange
        var sut = new MyClass();
        var input = "test";

        // Act
        var result = sut.Process(input);

        // Assert
        Assert.Equal("TEST", result);
    }

    [Theory]
    [InlineData("")]
    [InlineData(null)]
    public void Process_InvalidInput_ThrowsArgumentException(string input)
    {
        // Arrange
        var sut = new MyClass();

        // Act & Assert
        Assert.Throws<ArgumentException>(() => sut.Process(input));
    }
}
```

### Documentation

- Use XML documentation comments
- Document all public APIs
- Include `<summary>`, `<param>`, `<returns>`, `<exception>`

Example:
```csharp
namespace YourProject;

/// <summary>
/// Provides functionality for processing data.
/// </summary>
public class MyClass
{
    /// <summary>
    /// Processes the input string and converts it to uppercase.
    /// </summary>
    /// <param name="input">The input string to process.</param>
    /// <returns>The processed string in uppercase.</returns>
    /// <exception cref="ArgumentException">Thrown when input is null or empty.</exception>
    /// <example>
    /// <code>
    /// var processor = new MyClass();
    /// var result = processor.Process("hello");
    /// // result is "HELLO"
    /// </code>
    /// </example>
    public string Process(string input)
    {
        if (string.IsNullOrEmpty(input))
        {
            throw new ArgumentException("Input cannot be null or empty.", nameof(input));
        }

        return input.ToUpperInvariant();
    }
}
```

## Project Structure

```
project/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ YourProject/
‚îÇ       ‚îú‚îÄ‚îÄ YourProject.csproj
‚îÇ       ‚îú‚îÄ‚îÄ Class1.cs
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ YourProject.Tests/
‚îÇ       ‚îú‚îÄ‚îÄ YourProject.Tests.csproj
‚îÇ       ‚îú‚îÄ‚îÄ Class1Tests.cs
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ docs/                    # Project documentation
‚îú‚îÄ‚îÄ .editorconfig            # Code style configuration
‚îú‚îÄ‚îÄ Directory.Build.props    # Shared MSBuild properties
‚îú‚îÄ‚îÄ Directory.Packages.props # Central package management
‚îú‚îÄ‚îÄ YourProject.sln          # Solution file
‚îú‚îÄ‚îÄ README.md                # Project overview (allowed in root)
‚îú‚îÄ‚îÄ CHANGELOG.md             # Version history (allowed in root)
‚îî‚îÄ‚îÄ LICENSE                  # Project license (allowed in root)
```

## Nullable Reference Types

- Enable nullable reference types
- Use `?` for nullable types
- Use null-forgiving operator `!` sparingly

Example:
```csharp
public class UserService
{
    private readonly ILogger<UserService> _logger;

    public UserService(ILogger<UserService> logger)
    {
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));
    }

    public User? FindUser(string? username)
    {
        if (string.IsNullOrEmpty(username))
        {
            return null;
        }

        // Implementation
        return new User { Username = username };
    }

    public User GetUser(string username)
    {
        var user = FindUser(username);
        return user ?? throw new InvalidOperationException("User not found");
    }
}
```

## Async/Await Best Practices

- Use `async`/`await` for I/O operations
- Don't block on async code
- Use `ConfigureAwait(false)` in libraries
- Return `Task` or `ValueTask`

Example:
```csharp
public class DataService
{
    private readonly HttpClient _httpClient;

    public async Task<string> FetchDataAsync(string url, CancellationToken cancellationToken = default)
    {
        var response = await _httpClient.GetAsync(url, cancellationToken).ConfigureAwait(false);
        response.EnsureSuccessStatusCode();
        
        return await response.Content.ReadAsStringAsync(cancellationToken).ConfigureAwait(false);
    }
}
```

## CI/CD Requirements

Must include GitHub Actions workflows for:

1. **Testing** (`dotnet-test.yml`):
   - Test on ubuntu-latest, windows-latest, macos-latest
   - Test on .NET 8.0
   - Upload coverage reports

2. **Linting** (`dotnet-lint.yml`):
   - Format check: `dotnet format --verify-no-changes`
   - Build: `dotnet build --no-incremental`
   - Analyzers enabled

## Package Publication

### Publishing to NuGet

**Prerequisites:**
1. Create account at https://www.nuget.org
2. Generate API key from account settings
3. Add `NUGET_API_KEY` to GitHub repository secrets

**Publishing Workflow:**

1. Update version in .csproj
2. Update CHANGELOG.md
3. Run quality checks:
   ```bash
   dotnet format --verify-no-changes
   dotnet build --configuration Release
   dotnet test --configuration Release
   ```

4. Pack: `dotnet pack --configuration Release`
5. Create git tag: `git tag v1.0.0 && git push --tags`
6. GitHub Actions automatically publishes to NuGet
7. Or manual publish: `dotnet nuget push bin/Release/*.nupkg --api-key $NUGET_API_KEY --source https://api.nuget.org/v3/index.json`

**Publishing Checklist:**

- ‚úÖ All tests passing
- ‚úÖ Code formatted (`dotnet format`)
- ‚úÖ No build warnings
- ‚úÖ Version updated in .csproj
- ‚úÖ CHANGELOG.md updated
- ‚úÖ README.md up to date
- ‚úÖ LICENSE file present
- ‚úÖ XML documentation generated
- ‚úÖ Package metadata complete
- ‚úÖ Verify with `dotnet pack`

**Semantic Versioning:**

Use `<Version>` in .csproj with SemVer:
- **MAJOR**: Breaking API changes
- **MINOR**: New features (backwards compatible)
- **PATCH**: Bug fixes (backwards compatible)

<!-- CSHARP:END -->


<!-- RULEBOOK:SKILL:languages/c:END -->

<!-- RULEBOOK:SKILL:languages/c:START -->
<!-- C:START -->
# C Project Rules

## Agent Automation Commands

**CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow).

```bash
# Complete quality check sequence:
clang-format --dry-run --Werror src/**/*.c  # Format check
make lint                 # Linting (if configured)
make test                 # All tests (100% pass)
make                      # Build verification

# Memory safety (recommended):
valgrind --leak-check=full ./build/test  # Memory leak check
```

## C Configuration

**CRITICAL**: Use C11 or C17 standard with strict warnings enabled.

- **Standard**: C11 or C17
- **Compiler**: GCC 11+ or Clang 14+
- **Build System**: CMake 3.20+ (recommended) or Make
- **Warnings**: Treat all warnings as errors
- **Sanitizers**: ASAN, UBSAN for memory safety

### CMakeLists.txt Requirements

```cmake
cmake_minimum_required(VERSION 3.20)
project(YourProject C)

set(CMAKE_C_STANDARD 17)
set(CMAKE_C_STANDARD_REQUIRED ON)
set(CMAKE_C_EXTENSIONS OFF)

# Compiler warnings
if(MSVC)
  add_compile_options(/W4 /WX)
else()
  add_compile_options(-Wall -Wextra -Werror -pedantic)
endif()

# Enable sanitizers in Debug mode
if(CMAKE_BUILD_TYPE STREQUAL "Debug")
  add_compile_options(-fsanitize=address,undefined)
  add_link_options(-fsanitize=address,undefined)
endif()

# Source files
add_executable(${PROJECT_NAME} src/main.c src/module.c)

# Include directories
target_include_directories(${PROJECT_NAME} PUBLIC include)

# Enable testing
enable_testing()
add_subdirectory(tests)
```

## Code Quality Standards

### Mandatory Quality Checks

**CRITICAL**: After implementing ANY feature, you MUST run these commands in order.

**IMPORTANT**: These commands MUST match your GitHub Actions workflows to prevent CI/CD failures!

```bash
# Pre-Commit Checklist (MUST match .github/workflows/*.yml)

# 1. Format check (matches workflow - use --dry-run, not -i!)
clang-format --dry-run --Werror src/**/*.c include/**/*.h tests/**/*.c

# 2. Static analysis (matches workflow)
clang-tidy src/**/*.c -- -std=c17 -Wall -Wextra -Werror

# 3. Build with warnings as errors (matches workflow)
cmake -B build -DCMAKE_BUILD_TYPE=Release -DCMAKE_C_FLAGS="-Werror -Wall -Wextra -pedantic"
cmake --build build

# 4. Run all tests (MUST pass 100% - matches workflow)
ctest --test-dir build --output-on-failure --verbose

# 5. Check with Address Sanitizer (matches workflow)
cmake -B build-asan -DCMAKE_BUILD_TYPE=Debug \
  -DCMAKE_C_FLAGS="-fsanitize=address,undefined -g"
cmake --build build-asan
ctest --test-dir build-asan --output-on-failure

# 6. Check with Valgrind (matches workflow)
valgrind --leak-check=full --error-exitcode=1 ./build/YourProject

# 7. Check coverage (matches workflow)
cmake -B build-cov -DCMAKE_BUILD_TYPE=Coverage \
  -DCMAKE_C_FLAGS="-fprofile-arcs -ftest-coverage"
cmake --build build-cov
ctest --test-dir build-cov
gcov build-cov/CMakeFiles/YourProject.dir/src/*.gcno
lcov --capture --directory build-cov --output-file coverage.info
lcov --list coverage.info

# If ANY fails: ‚ùå DO NOT COMMIT - Fix first!
```

**If ANY of these fail, you MUST fix the issues before committing.**

**Why This Matters:**
- Running different commands locally than in CI causes "works on my machine" failures
- CI/CD failures happen when local checks differ from workflows
- Example: Using `clang-format -i` locally but `--dry-run --Werror` in CI = failure
- Example: Missing `-Werror` flag = warnings pass locally but fail in CI
- Example: Skipping sanitizers locally = CI catches memory bugs, use-after-free, buffer overflows
- Example: Not running Valgrind = memory leaks pass locally but fail in CI

### Formatting

- Use clang-format for consistent code style
- Configuration in `.clang-format`
- Check formatting in CI (don't auto-format)

Example `.clang-format`:
```yaml
Language: C
BasedOnStyle: LLVM
IndentWidth: 4
ColumnLimit: 100
AllowShortFunctionsOnASingleLine: Empty
BreakBeforeBraces: Attach
AlignConsecutiveMacros: true
```

### Static Analysis

- Use clang-tidy for static analysis
- Configuration in `.clang-tidy`
- Enable modernize and bugprone checks

Example `.clang-tidy`:
```yaml
Checks: >
  -*,
  bugprone-*,
  clang-analyzer-*,
  modernize-*,
  readability-*,
  performance-*,
  portability-*

CheckOptions:
  - key: readability-identifier-naming.FunctionCase
    value: lower_case
  - key: readability-identifier-naming.VariableCase
    value: lower_case
```

### Testing

- **Framework**: Unity, Check, or CTest
- **Location**: `/tests` directory
- **Coverage**: Must meet threshold (80%+)
- **Sanitizers**: ASAN, UBSAN, Valgrind
- **Memory Safety**: Zero memory leaks

Example Unity test:
```c
#include "unity.h"
#include "module.h"

void setUp(void) {
    // Setup before each test
}

void tearDown(void) {
    // Cleanup after each test
}

void test_function_should_return_expected_value(void) {
    int result = my_function(10);
    TEST_ASSERT_EQUAL_INT(20, result);
}

void test_function_should_handle_null_pointer(void) {
    TEST_ASSERT_NULL(my_function_with_null(NULL));
}

int main(void) {
    UNITY_BEGIN();
    RUN_TEST(test_function_should_return_expected_value);
    RUN_TEST(test_function_should_handle_null_pointer);
    return UNITY_END();
}
```

## Memory Safety

**CRITICAL**: Always check for memory issues.

### Required Checks

1. **Address Sanitizer (ASAN)**:
   ```bash
   gcc -fsanitize=address -g -o program main.c
   ./program
   ```

2. **Undefined Behavior Sanitizer (UBSAN)**:
   ```bash
   gcc -fsanitize=undefined -g -o program main.c
   ./program
   ```

3. **Valgrind**:
   ```bash
   valgrind --leak-check=full --show-leak-kinds=all ./program
   ```

4. **Static Analysis**:
   ```bash
   clang-tidy src/**/*.c
   cppcheck --enable=all --error-exitcode=1 src/
   ```

### Common Memory Issues to Prevent

```c
// ‚ùå BAD: Memory leak
char *buffer = malloc(100);
// ... use buffer ...
// Missing free()

// ‚úÖ GOOD: Proper cleanup
char *buffer = malloc(100);
if (buffer == NULL) {
    return ERROR_NO_MEMORY;
}
// ... use buffer ...
free(buffer);
buffer = NULL;

// ‚ùå BAD: Use after free
char *ptr = malloc(10);
free(ptr);
strcpy(ptr, "test");  // UNDEFINED BEHAVIOR!

// ‚úÖ GOOD: NULL after free
char *ptr = malloc(10);
free(ptr);
ptr = NULL;
if (ptr != NULL) {
    strcpy(ptr, "test");
}

// ‚ùå BAD: Buffer overflow
char buffer[10];
strcpy(buffer, "This is too long");  // BUFFER OVERFLOW!

// ‚úÖ GOOD: Bounds checking
char buffer[10];
strncpy(buffer, "Safe", sizeof(buffer) - 1);
buffer[sizeof(buffer) - 1] = '\0';
```

## Best Practices

### DO's ‚úÖ

- **CHECK** return values from all functions
- **VALIDATE** all pointer arguments for NULL
- **FREE** all allocated memory
- **USE** const for immutable pointers
- **LIMIT** variable scope
- **ZERO** memory after free for security
- **BOUNDS** check all array accesses
- **SANITIZE** all inputs

### DON'Ts ‚ùå

- **NEVER** ignore compiler warnings
- **NEVER** assume malloc succeeds
- **NEVER** use gets() (use fgets())
- **NEVER** use strcpy() (use strncpy() or strlcpy())
- **NEVER** use sprintf() (use snprintf())
- **NEVER** dereference NULL pointers
- **NEVER** return pointers to stack variables
- **NEVER** skip sanitizer checks

## Security Guidelines

1. **Input Validation**: Validate all external inputs
2. **Buffer Safety**: Always check bounds
3. **Integer Overflow**: Check arithmetic operations
4. **Format String**: Never use user input as format string
5. **Memory Zeroization**: Zero sensitive data after use

Example secure code:
```c
#include <string.h>
#include <stdlib.h>
#include <stdio.h>

// Secure string copy with bounds checking
int safe_strcpy(char *dest, size_t dest_size, const char *src) {
    if (dest == NULL || src == NULL || dest_size == 0) {
        return -1;
    }
    
    size_t src_len = strlen(src);
    if (src_len >= dest_size) {
        return -1;  // Not enough space
    }
    
    strncpy(dest, src, dest_size - 1);
    dest[dest_size - 1] = '\0';
    return 0;
}

// Secure memory cleanup
void secure_free(void **ptr, size_t size) {
    if (ptr == NULL || *ptr == NULL) {
        return;
    }
    
    // Zero memory before free
    memset(*ptr, 0, size);
    free(*ptr);
    *ptr = NULL;
}
```

<!-- C:END -->

<!-- RULEBOOK:SKILL:languages/c:END -->

<!-- RULEBOOK:SKILL:languages/cpp:START -->
<!-- CPP:START -->
# C/C++ Project Rules

## Agent Automation Commands

**CRITICAL**: Execute these commands after EVERY implementation (see AGENT_AUTOMATION module for full workflow).

```bash
# Complete quality check sequence:
clang-format --dry-run --Werror src/**/*.cpp  # Format check
clang-tidy src/**/*.cpp   # Linting
make test                 # All tests (100% pass)
make                      # Build verification

# Additional checks:
cppcheck --enable=all src/  # Static analysis
valgrind --leak-check=full ./build/test  # Memory check
```

## C/C++ Configuration

**CRITICAL**: Use C++20 or C++23 with modern CMake.

- **C++ Standard**: C++20 or C++23
- **CMake**: 3.25+
- **Compiler**: GCC 11+, Clang 15+, or MSVC 19.30+
- **Build System**: CMake (recommended) or Meson
- **Package Manager**: Conan or vcpkg

### CMakeLists.txt Requirements

```cmake
cmake_minimum_required(VERSION 3.25)
project(YourProject VERSION 1.0.0 LANGUAGES CXX)

# C++ Standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Compiler warnings
if(MSVC)
    add_compile_options(/W4 /WX)
else()
    add_compile_options(-Wall -Wextra -Wpedantic -Werror)
endif()

# Export compile commands for tooling
set(CMAKE_EXPORT_COMPILE_COMMANDS ON)

# Project options
option(BUILD_TESTING "Build tests" ON)
option(BUILD_DOCS "Build documentation" ON)
option(ENABLE_SANITIZERS "Enable sanitizers" ON)

# Dependencies (using FetchContent or find_package)
include(FetchContent)

FetchContent_Declare(
    googletest
    GIT_REPOSITORY https://github.com/google/googletest.git
    GIT_TAG v1.14.0
)
FetchContent_MakeAvailable(googletest)

# Library
add_library(${PROJECT_NAME}
    src/your_module.cpp
    src/your_module.hpp
)

target_include_directories(${PROJECT_NAME}
    PUBLIC
        $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include>
        $<INSTALL_INTERFACE:include>
    PRIVATE
        ${CMAKE_CURRENT_SOURCE_DIR}/src
)

# Enable sanitizers in debug
if(ENABLE_SANITIZERS AND CMAKE_BUILD_TYPE MATCHES Debug)
    target_compile_options(${PROJECT_NAME} PRIVATE
        -fsanitize=address
        -fsanitize=undefined
        -fno-omit-frame-pointer
    )
    target_link_options(${PROJECT_NAME} PRIVATE
        -fsanitize=address
        -fsanitize=undefined
    )
endif()

# Tests
if(BUILD_TESTING)
    enable_testing()
    add_subdirectory(tests)
endif()

# Installation
install(TARGETS ${PROJECT_NAME}
    EXPORT ${PROJECT_NAME}Targets
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
    RUNTIME DESTINATION bin
    INCLUDES DESTINATION include
)
```

## Code Quality Standards

### Mandatory Quality Checks

**CRITICAL**: After implementing ANY feature, you MUST run these commands in order.

**IMPORTANT**: These commands MUST match your GitHub Actions workflows to prevent CI/CD failures!

```bash
# Pre-Commit Checklist (MUST match .github/workflows/*.yml)

# 1. Format check (matches workflow - use --dry-run, not -i!)
clang-format --dry-run --Werror src/**/*.{cpp,hpp} tests/**/*.{cpp,hpp}

# 2. Static analysis (matches workflow)
clang-tidy src/**/*.cpp -- -std=c++20

# 3. Build (MUST pass with no warnings - matches workflow)
cmake -B build -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS="-Werror"
cmake --build build

# 4. Run all tests (MUST pass 100% - matches workflow)
ctest --test-dir build --output-on-failure

# 5. Check with sanitizers (matches workflow)
cmake -B build-asan -DENABLE_SANITIZERS=ON
cmake --build build-asan
ctest --test-dir build-asan

# 6. Check coverage (matches workflow)
cmake -B build-cov -DCMAKE_BUILD_TYPE=Coverage
cmake --build build-cov
ctest --test-dir build-cov
gcov build-cov/CMakeFiles/YourProject.dir/src/*.gcno

# If ANY fails: ‚ùå DO NOT COMMIT - Fix first!
```

**Why This Matters:**
- CI/CD failures happen when local commands differ from workflows
- Example: Using `clang-format -i` locally but `--dry-run --Werror` in CI = failure
- Example: Missing `-Werror` flag = warnings pass locally but fail in CI
- Example: Skipping sanitizers locally = CI catches memory bugs you missed
```

**If ANY of these fail, you MUST fix the issues before committing.**

### Code Style

Use `.clang-format` for consistent formatting:

```yaml
---
Language: Cpp
BasedOnStyle: Google
IndentWidth: 4
ColumnLimit: 100
UseTab: Never
PointerAlignment: Left
ReferenceAlignment: Left
DerivePointerAlignment: false

# Includes
SortIncludes: CaseInsensitive
IncludeBlocks: Regroup
IncludeCategories:
  - Regex: '^<.*\.h>'
    Priority: 1
  - Regex: '^<.*>'
    Priority: 2
  - Regex: '.*'
    Priority: 3

# Braces
BreakBeforeBraces: Attach
AllowShortFunctionsOnASingleLine: Inline
AllowShortIfStatementsOnASingleLine: Never

# Spacing
SpaceAfterCStyleCast: false
SpaceAfterTemplateKeyword: true
SpaceBeforeParens: ControlStatements

# Modern C++
Standard: c++20
```

### Static Analysis

Use `.clang-tidy` for code analysis:

```yaml
---
Checks: >
  *,
  -abseil-*,
  -altera-*,
  -android-*,
  -fuchsia-*,
  -google-*,
  -llvm-*,
  -llvmlibc-*,
  -zircon-*,
  -readability-identifier-length,
  -modernize-use-trailing-return-type

CheckOptions:
  - key: readability-identifier-naming.NamespaceCase
    value: lower_case
  - key: readability-identifier-naming.ClassCase
    value: CamelCase
  - key: readability-identifier-naming.StructCase
    value: CamelCase
  - key: readability-identifier-naming.FunctionCase
    value: camelCase
  - key: readability-identifier-naming.VariableCase
    value: lower_case
  - key: readability-identifier-naming.ConstantCase
    value: UPPER_CASE
  - key: readability-identifier-naming.MemberCase
    value: lower_case_
  - key: readability-identifier-naming.PrivateMemberSuffix
    value: '_'

WarningsAsErrors: '*'
```

### Testing

- **Framework**: Google Test (recommended) or Catch2
- **Location**: `tests/` directory
- **Coverage**: gcov/lcov or llvm-cov
- **Coverage Threshold**: 95%+

Example test with Google Test:

```cpp
#include <gtest/gtest.h>
#include "your_module.hpp"

namespace your_namespace::tests {

class DataProcessorTest : public ::testing::Test {
protected:
    void SetUp() override {
        processor = std::make_unique<DataProcessor>();
    }

    void TearDown() override {
        processor.reset();
    }

    std::unique_ptr<DataProcessor> processor;
};

TEST_F(DataProcessorTest, ProcessValidInput) {
    const std::string input = "hello";
    const auto result = processor->process(input);
    
    EXPECT_EQ(result, "HELLO");
}

TEST_F(DataProcessorTest, ProcessEmptyInputThrows) {
    EXPECT_THROW(
        processor->process(""),
        std::invalid_argument
    );
}

TEST_F(DataProcessorTest, ProcessLargeInput) {
    const std::string input(1000, 'a');
    const auto result = processor->process(input);
    
    ASSERT_EQ(result.size(), 1000);
    EXPECT_TRUE(std::all_of(result.begin(), result.end(), 
        [](char c) { return std::isupper(c); }));
}

} // namespace your_namespace::tests
```

### Modern C++ Best Practices

- Use RAII for resource management
- Prefer `std::unique_ptr` and `std::shared_ptr` over raw pointers
- Use `const` and `constexpr` liberally
- Prefer `std::string_view` for read-only strings
- Use range-based for loops
- Use `auto` for type deduction when clear
- Avoid manual memory management

Example modern C++ code:

```cpp
#pragma once

#include <memory>
#include <string>
#include <string_view>
#include <vector>
#include <optional>
#include <expected>

namespace your_namespace {

/// @brief Processes data with various transformations
class DataProcessor {
public:
    DataProcessor() = default;
    ~DataProcessor() = default;
    
    // Delete copy constructor and assignment
    DataProcessor(const DataProcessor&) = delete;
    DataProcessor& operator=(const DataProcessor&) = delete;
    
    // Default move constructor and assignment
    DataProcessor(DataProcessor&&) noexcept = default;
    DataProcessor& operator=(DataProcessor&&) noexcept = default;
    
    /// @brief Process input string to uppercase
    /// @param input The input string to process
    /// @return Processed string or error
    /// @throws std::invalid_argument if input is empty
    [[nodiscard]] std::string process(std::string_view input) const;
    
    /// @brief Find value in data
    /// @param data The data to search
    /// @param key The key to find
    /// @return Optional value if found
    [[nodiscard]] std::optional<std::string> findValue(
        const std::vector<std::pair<std::string, std::string>>& data,
        std::string_view key
    ) const;
    
    /// @brief Process multiple items
    /// @param items Items to process
    /// @return Processed items
    [[nodiscard]] std::vector<std::string> processMany(
        const std::vector<std::string>& items
    ) const;

private:
    mutable std::mutex mutex_;
};

} // namespace your_namespace
```

Implementation:

```cpp
#include "your_module.hpp"
#include <algorithm>
#include <stdexcept>
#include <cctype>

namespace your_namespace {

std::string DataProcessor::process(std::string_view input) const {
    if (input.empty()) {
        throw std::invalid_argument("Input cannot be empty");
    }
    
    std::string result;
    result.reserve(input.size());
    
    std::transform(input.begin(), input.end(), 
                   std::back_inserter(result),
                   [](unsigned char c) { return std::toupper(c); });
    
    return result;
}

std::optional<std::string> DataProcessor::findValue(
    const std::vector<std::pair<std::string, std::string>>& data,
    std::string_view key
) const {
    auto it = std::find_if(data.begin(), data.end(),
        [key](const auto& pair) { return pair.first == key; });
    
    if (it != data.end()) {
        return it->second;
    }
    
    return std::nullopt;
}

std::vector<std::string> DataProcessor::processMany(
    const std::vector<std::string>& items
) const {
    std::vector<std::string> results;
    results.reserve(items.size());
    
    std::transform(items.begin(), items.end(),
                   std::back_inserter(results),
                   [this](const auto& item) { return process(item); });
    
    return results;
}

} // namespace your_namespace
```

## Documentation

Use Doxygen for API documentation:

```cpp
/**
 * @file your_module.hpp
 * @brief Data processing utilities
 * @author Your Name
 * @date 2024-10-23
 */

/**
 * @class DataProcessor
 * @brief Processes various data formats
 * 
 * This class provides thread-safe data processing capabilities.
 * All methods are const-correct and exception-safe.
 * 
 * @example
 * @code{.cpp}
 * DataProcessor processor;
 * auto result = processor.process("hello");
 * assert(result == "HELLO");
 * @endcode
 */
```

### Doxyfile Configuration:

```
PROJECT_NAME = "Your Project"
PROJECT_NUMBER = 1.0.0
OUTPUT_DIRECTORY = docs
GENERATE_HTML = YES
GENERATE_LATEX = NO
EXTRACT_ALL = YES
EXTRACT_PRIVATE = NO
EXTRACT_STATIC = YES
SOURCE_BROWSER = YES
INLINE_SOURCES = YES
RECURSIVE = YES
```

## Project Structure

```
project/
‚îú‚îÄ‚îÄ CMakeLists.txt          # CMake configuration
‚îú‚îÄ‚îÄ .clang-format           # Code formatting rules
‚îú‚îÄ‚îÄ .clang-tidy             # Static analysis rules
‚îú‚îÄ‚îÄ Doxyfile                # Documentation config
‚îú‚îÄ‚îÄ conanfile.txt           # Conan dependencies (optional)
‚îú‚îÄ‚îÄ vcpkg.json              # vcpkg dependencies (optional)
‚îú‚îÄ‚îÄ README.md               # Project overview
‚îú‚îÄ‚îÄ CHANGELOG.md            # Version history
‚îú‚îÄ‚îÄ LICENSE                 # Project license
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îî‚îÄ‚îÄ your_project/
‚îÇ       ‚îî‚îÄ‚îÄ your_module.hpp # Public headers
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ your_module.cpp     # Implementation
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ CMakeLists.txt
‚îÇ   ‚îî‚îÄ‚îÄ test_your_module.cpp
‚îú‚îÄ‚îÄ benchmarks/             # Performance benchmarks
‚îÇ   ‚îî‚îÄ‚îÄ benchmark_main.cpp
‚îî‚îÄ‚îÄ docs/                   # Project documentation
```

## Memory Safety

- Use RAII for all resource management
- Prefer stack allocation over heap
- Use smart pointers for heap allocation
- Never use raw `new`/`delete`
- Use containers instead of manual arrays
- Check all pointer dereferences

Example:

```cpp
// Good: RAII with smart pointers
class FileManager {
public:
    explicit FileManager(std::string_view filename) 
        : file_(std::make_unique<std::ifstream>(filename.data())) {
        if (!file_->is_open()) {
            throw std::runtime_error("Failed to open file");
        }
    }
    
    // RAII - file automatically closed
    ~FileManager() = default;
    
    [[nodiscard]] std::string readLine() {
        std::string line;
        if (std::getline(*file_, line)) {
            return line;
        }
        throw std::runtime_error("Failed to read line");
    }

private:
    std::unique_ptr<std::ifstream> file_;
};

// Bad: Manual memory management
class BadFileManager {
public:
    BadFileManager(const char* filename) {
        file = new std::ifstream(filename);  // ‚ùå Manual allocation
    }
    
    ~BadFileManager() {
        delete file;  // ‚ùå Manual deletion (error-prone)
    }

private:
    std::ifstream* file;  // ‚ùå Raw pointer
};
```

## Error Handling

- Use exceptions for exceptional cases
- Use `std::expected` (C++23) or `std::optional` for expected failures
- Create custom exception classes
- Document all exceptions with `@throws`

Example:

```cpp
#include <stdexcept>
#include <optional>

namespace your_namespace {

class ValidationError : public std::runtime_error {
public:
    explicit ValidationError(std::string_view message, std::string_view field)
        : std::runtime_error(std::string(message))
        , field_(field) {}
    
    [[nodiscard]] const std::string& field() const noexcept { return field_; }

private:
    std::string field_;
};

class DataValidator {
public:
    /// @throws ValidationError if data is invalid
    void validate(std::string_view data) const {
        if (data.empty()) {
            throw ValidationError("Data cannot be empty", "data");
        }
    }
    
    /// @return Optional value if valid, nullopt otherwise
    [[nodiscard]] std::optional<int> tryParse(std::string_view str) const noexcept {
        try {
            return std::stoi(std::string(str));
        } catch (...) {
            return std::nullopt;
        }
    }
};

} // namespace your_namespace
```

## Threading & Concurrency

- Use `std::thread`, `std::jthread` (C++20), or `std::async`
- Use `std::mutex`, `std::shared_mutex` for synchronization
- Prefer `std::atomic` for simple shared state
- Use `std::lock_guard` or `std::scoped_lock`

Example:

```cpp
#include <mutex>
#include <shared_mutex>
#include <thread>
#include <atomic>

class ThreadSafeCounter {
public:
    void increment() {
        std::scoped_lock lock(mutex_);
        ++counter_;
    }
    
    [[nodiscard]] int get() const {
        std::shared_lock lock(mutex_);
        return counter_;
    }

private:
    mutable std::shared_mutex mutex_;
    int counter_{0};
};

// For simple atomics
class AtomicCounter {
public:
    void increment() noexcept {
        counter_.fetch_add(1, std::memory_order_relaxed);
    }
    
    [[nodiscard]] int get() const noexcept {
        return counter_.load(std::memory_order_relaxed);
    }

private:
    std::atomic<int> counter_{0};
};
```

## CI/CD Requirements

Must include GitHub Actions workflows for:

1. **Testing** (`cpp-test.yml`):
   - Test on ubuntu-latest, windows-latest, macos-latest
   - Test with GCC, Clang, MSVC
   - Upload coverage reports

2. **Linting** (`cpp-lint.yml`):
   - clang-format check
   - clang-tidy analysis
   - cppcheck static analysis

## Package Publication

### Publishing C/C++ Libraries

**Options:**
1. **Conan Center**: Public Conan repository
2. **vcpkg**: Microsoft's package manager
3. **GitHub Releases**: Binary releases
4. **Header-only**: Single-file distribution

### Conan Publication

**conanfile.py:**

```python
from conan import ConanFile
from conan.tools.cmake import CMakeToolchain, CMake, cmake_layout

class YourProjectConan(ConanFile):
    name = "your-project"
    version = "1.0.0"
    license = "MIT"
    author = "Your Name your.email@example.com"
    url = "https://github.com/your-org/your-project"
    description = "Short description"
    topics = ("cpp", "library")
    settings = "os", "compiler", "build_type", "arch"
    
    options = {
        "shared": [True, False],
        "fPIC": [True, False]
    }
    default_options = {
        "shared": False,
        "fPIC": True
    }
    
    exports_sources = "CMakeLists.txt", "src/*", "include/*"
    
    def layout(self):
        cmake_layout(self)
    
    def generate(self):
        tc = CMakeToolchain(self)
        tc.generate()
    
    def build(self):
        cmake = CMake(self)
        cmake.configure()
        cmake.build()
    
    def package(self):
        cmake = CMake(self)
        cmake.install()
    
    def package_info(self):
        self.cpp_info.libs = ["your-project"]
```

### vcpkg Publication

**vcpkg.json:**

```json
{
  "name": "your-project",
  "version": "1.0.0",
  "description": "Short description",
  "homepage": "https://github.com/your-org/your-project",
  "license": "MIT",
  "dependencies": [
    {
      "name": "vcpkg-cmake",
      "host": true
    },
    {
      "name": "vcpkg-cmake-config",
      "host": true
    }
  ]
}
```

### Publishing Checklist:

- ‚úÖ All tests passing with sanitizers
- ‚úÖ clang-tidy clean
- ‚úÖ clang-format applied
- ‚úÖ Documentation generated
- ‚úÖ Version updated in CMakeLists.txt
- ‚úÖ CHANGELOG.md updated
- ‚úÖ README.md with build instructions
- ‚úÖ LICENSE file present
- ‚úÖ CMake config for find_package support
- ‚úÖ Conan recipe or vcpkg portfile

<!-- CPP:END -->


<!-- RULEBOOK:SKILL:languages/cpp:END -->

<!-- RULEBOOK:SKILL:core/agent-automation:START -->
<!-- AGENT_AUTOMATION:START -->
# Agent Automation Rules

**CRITICAL**: Mandatory workflow that AI agents MUST execute after EVERY implementation.

## ‚ö†Ô∏è TOKEN OPTIMIZATION (MANDATORY FOR HAIKU)

**Claude Haiku has limited context. Every token counts.**

### Core Rules ‚úÖ
1. **Output code, not explanation** - Put logic in comments, not markdown
2. **Minimal reports** - Say "‚úÖ Done" instead of detailed status reports
3. **No markdown abuse** - No unnecessary headings, tables, or emoji status lines
4. **Combine outputs** - One response instead of multiple small ones
5. **Comments > Documentation** - Use code comments for explaining logic

### Tokens Saved üí∞
- Remove status emoji lines: **~500 tokens/task**
- Skip "Next Steps" sections: **~100 tokens/task**
- Eliminate markdown tables: **~200 tokens/task**
- Use concise commit messages: **~50 tokens/task**

**Total per task**: ~850 tokens saved = much more context for actual work

### Examples

‚ùå BAD (Wastes tokens):
```
‚úÖ Implementation Complete

üìù Changes:
- Added UserService
- Added middleware
- Updated routes

üß™ Quality Checks:
- ‚úÖ Type check: Passed
- ‚úÖ Lint: 0 warnings
- ‚úÖ Tests: 45/45 passed
- ‚úÖ Coverage: 96%
```

‚úÖ GOOD (Efficient):
```
‚úÖ Done. UserService + middleware committed.
```

## Workflow Overview

After completing ANY feature, bug fix, or code change, execute this workflow in order:

### Step 1: Quality Checks (MANDATORY)

Run these checks in order - ALL must pass:

```bash
1. Type check (if applicable)
2. Lint (MUST pass with ZERO warnings)
3. Format code
4. Run ALL tests (MUST pass 100%)
5. Verify coverage meets threshold (default 95%)
```

**Language-specific commands**: See your language template (TYPESCRIPT, RUST, PYTHON, etc.) for exact commands.

**IF ANY CHECK FAILS:**
- ‚ùå STOP immediately
- ‚ùå DO NOT proceed
- ‚ùå DO NOT commit
- ‚úÖ Fix the issue first
- ‚úÖ Re-run ALL checks

**‚ö†Ô∏è TOKEN OPTIMIZATION**:
- Output only pass/fail status for each check
- Do NOT output detailed logs or test results
- Do NOT create status tables or emoji reports
- Use concise format: "‚úÖ type-check pass" or "‚ùå tests fail: reason"

### Step 2: Capture to Persistent Memory

**IMPORTANT**: Save implementation insights and decisions to persistent memory for context across future sessions.

```bash
# 1. Identify key learnings from this implementation:
#    - Design decisions made
#    - Patterns discovered or applied
#    - Gotchas or edge cases encountered
#    - Performance insights
#    - Test coverage notes

# 2. Save to memory (via MCP or CLI):
rulebook memory save "<content>" --type feature --title "Brief title" --tags tag1,tag2

# 3. Example:
rulebook memory save "Implemented OAuth token refresh with 30-min expiry. Key gotcha: tokens expire silently without warning on API calls - must check headers before retry. Pattern: Use interceptor middleware for transparent refresh." --type feature --title "OAuth token refresh implementation" --tags auth,oauth,gotchas
```

**Memory Auto-Capture**: If memory auto-capture is enabled in `.rulebook`, significant implementation outputs are automatically captured. Review and augment with additional context as needed.

### Step 3: Security & Dependency Audits

```bash
# Check for vulnerabilities (language-specific)
# Check for outdated dependencies (informational)
# Find unused dependencies (optional)
```

**Language-specific commands**: See your language template for audit commands.

**IF VULNERABILITIES FOUND:**
- ‚úÖ Attempt automatic fix
- ‚úÖ Document if auto-fix fails
- ‚úÖ Include in Step 5 report
- ‚ùå Never ignore critical/high vulnerabilities without user approval

### Step 4: Update Rulebook Tasks

If using rulebook task management:

```bash
# Mark implemented tasks as completed
rulebook task update <task-id> --status completed

# Update any blocked/pending tasks
rulebook task update <task-id> --status blocked --reason "explanation"
```

### Step 5: Update OpenSpec Tasks

If `openspec/` directory exists:

```bash
# Mark completed tasks as [DONE]
# Update in-progress tasks
# Add new tasks if discovered
# Update progress percentages
# Document deviations or blockers
```

### Step 6: Update Documentation

```bash
# Update ROADMAP.md (if feature is milestone)
# Update CHANGELOG.md (conventional commits format)
# Update feature specs (if implementation differs)
# Update README.md (if public API changed)
```

### Step 7: Git Commit

**ONLY after ALL above steps pass:**

**‚ö†Ô∏è CRITICAL: All commit messages MUST be in English**

```bash
git add .
git commit -m "<type>(<scope>): <description>

- Detailed change 1
- Detailed change 2
- Tests: [describe coverage]
- Coverage: X% (threshold: 95%)
- Memory: [saved key learnings to persistent memory]

Closes #<issue> (if applicable)"
```

**Commit Types**: `feat`, `fix`, `docs`, `refactor`, `perf`, `test`, `build`, `ci`, `chore`

**Language Requirement**: Commit messages must be written in English. Never use Portuguese, Spanish, or any other language.

### Step 8: Report to User (Minimal Token Output)

**‚ö†Ô∏è CRITICAL: Minimize report to save tokens**

**‚úÖ MINIMAL REPORT (Preferred - Saves ~500 tokens):**
```
‚úÖ Done. Committed: <hash>
```

**‚úÖ SHORT REPORT (If needed - Only ~100 tokens):**
```
‚úÖ Implementation complete
- Files changed: X
- Tests: pass
- Coverage: X%
- Committed
```

**‚ùå NEVER OUTPUT LONG REPORTS (Wastes tokens):**
- ‚ùå Don't create "Implementation Complete" sections
- ‚ùå Don't list all quality checks with emojis
- ‚ùå Don't show commit messages verbatim
- ‚ùå Don't add "Next Steps" sections
- ‚ùå Don't create status tables or boxes

**Why**: Long reports add 500-1000+ tokens per task. For Haiku (limited context), use minimal format.

## Automation Exceptions

Skip steps ONLY when:

1. **Exploratory Code**: User says "experimental", "draft", "try"
   - Still run quality checks
   - Don't commit

2. **User Explicitly Requests**: User says "skip tests", "no commit"
   - Only skip requested step
   - Warn about skipped steps

3. **Emergency Hotfix**: Critical production bug
   - Run minimal checks
   - Document technical debt

**In ALL other cases: Execute complete workflow**

## Error Recovery

If workflow fails 3+ times:

```bash
1. Create backup branch
2. Reset to last stable commit
3. Report to user with error details
4. Request guidance or try alternative approach
```

## Best Practices

### DO's ‚úÖ
- ALWAYS run complete workflow
- ALWAYS update OpenSpec and documentation
- ALWAYS use conventional commits
- ALWAYS report summary to user
- ASK before skipping steps

### DON'Ts ‚ùå
- NEVER skip quality checks without permission
- NEVER commit failing tests
- NEVER commit linting errors
- NEVER skip documentation updates
- NEVER assume user wants to skip automation
- NEVER commit debug code or secrets

## Summary

**Complete workflow after EVERY implementation:**

1. ‚úÖ Quality checks (type, lint, format, test, coverage)
2. ‚úÖ Capture to persistent memory (save learnings and decisions)
3. ‚úÖ Security audit
4. ‚úÖ Update rulebook tasks
5. ‚úÖ Update OpenSpec tasks (if applicable)
6. ‚úÖ Update documentation
7. ‚úÖ Git commit (conventional format)
8. ‚úÖ Report summary to user

**Only skip with explicit user permission and document why.**

## Persistent Memory Best Practices

### What to Capture
- **Design decisions**: Why a particular approach was chosen
- **Patterns**: Reusable solutions discovered during implementation
- **Gotchas**: Edge cases, limitations, or surprising behaviors
- **Performance insights**: Optimization lessons or bottleneck discoveries
- **Bug fixes**: Root cause and resolution for future reference

### How to Capture
```bash
# Via CLI
rulebook memory save "<detailed content>" --type <type> --title "Short title" --tags tag1,tag2

# Memory types: bugfix, feature, refactor, decision, discovery, change, observation

# Example: Feature capture
rulebook memory save "Implemented async batch processing for large datasets. Pattern: use queue with worker threads (maxWorkers=4). Gotcha: Queue memory grows unbounded - added max size limit with drop strategy. Tests: Added batch-size edge cases." --type feature --title "Async batch processing implementation" --tags performance,queues,patterns
```

### Search Previous Context
Before implementing similar features, search memory for past learnings:
```bash
rulebook memory search "batch processing" --mode hybrid
```

This surfaces past decisions and patterns to avoid redundant work and preserve institutional knowledge.

<!-- AGENT_AUTOMATION:END -->

<!-- RULEBOOK:SKILL:core/agent-automation:END -->

<!-- RULEBOOK:SKILL:core/dag:START -->
<!-- DAG:START -->
# Dependency Architecture Guidelines (DAG)

**CRITICAL**: Maintain a clean dependency graph (DAG) to prevent circular dependencies and ensure maintainable architecture.

## Core Principles

### No Circular Dependencies
- **NEVER** create circular dependencies between components
- **ALWAYS** ensure dependencies form a Directed Acyclic Graph (DAG)
- **ALWAYS** validate dependency structure before committing

### Layer Separation
- **ALWAYS** maintain clear layer boundaries
- **ALWAYS** ensure higher layers depend only on lower layers
- **NEVER** allow lower layers to depend on higher layers

### Interface Boundaries
- **ALWAYS** use interfaces for cross-component communication
- **ALWAYS** define clear contracts between components
- **NEVER** create tight coupling between components

## Dependency Rules

### Layer Architecture

**Layer 1: Foundation**
- Utils, helpers, utilities
- Type definitions
- Configuration management
- Base constants and enums

**Layer 2: Core**
- Core business logic
- Data models and schemas
- Base services and repositories
- Domain entities

**Layer 3: Features**
- Feature implementations
- Business logic
- API endpoints
- Service orchestration

**Layer 4: Presentation**
- UI components
- CLI interfaces
- API controllers
- View models

### Dependency Flow

```
Foundation ‚Üí Core ‚Üí Features ‚Üí Presentation
```

**Rules:**
- ‚úÖ Foundation can depend on nothing (or external libraries only)
- ‚úÖ Core can depend on Foundation
- ‚úÖ Features can depend on Core and Foundation
- ‚úÖ Presentation can depend on Features, Core, and Foundation
- ‚ùå Foundation CANNOT depend on Core, Features, or Presentation
- ‚ùå Core CANNOT depend on Features or Presentation
- ‚ùå Features CANNOT depend on Presentation

## Component Graph Structure

### Example Valid DAG

```
Core
  ‚îú‚îÄ‚îÄ Utils
  ‚îú‚îÄ‚îÄ Types
  ‚îî‚îÄ‚îÄ Config

Features
  ‚îú‚îÄ‚îÄ Feature A
  ‚îÇ   ‚îî‚îÄ‚îÄ Core
  ‚îî‚îÄ‚îÄ Feature B
      ‚îú‚îÄ‚îÄ Core
      ‚îî‚îÄ‚îÄ Feature A

Presentation
  ‚îú‚îÄ‚îÄ CLI
  ‚îÇ   ‚îî‚îÄ‚îÄ Features
  ‚îî‚îÄ‚îÄ API
      ‚îî‚îÄ‚îÄ Features
```

### Invalid Patterns (Circular Dependencies)

```
‚ùå Feature A ‚Üí Feature B ‚Üí Feature A
‚ùå Core ‚Üí Feature ‚Üí Core
‚ùå Utils ‚Üí Core ‚Üí Utils
```

## Verification

### Before Committing

**MANDATORY**: Verify dependency structure:

```bash
# Check for circular dependencies
# Add your dependency check command here
# Examples:
# - TypeScript: tsc --noEmit (catches import cycles)
# - Rust: cargo check (catches circular dependencies)
# - Python: pylint --disable=all --enable=import-error
# - Go: go vet ./...
```

### Dependency Analysis Tools

**TypeScript/JavaScript:**
```bash
# Use madge to detect circular dependencies
npx madge --circular src/

# Use dependency-cruiser
npx dependency-cruiser --validate src/
```

**Rust:**
```bash
# Cargo automatically detects circular dependencies
cargo check
```

**Python:**
```bash
# Use vulture or pylint
pylint --disable=all --enable=import-error src/
```

**Go:**
```bash
# Use go vet
go vet ./...
```

## Best Practices

### DO's ‚úÖ

- **ALWAYS** maintain clear layer boundaries
- **ALWAYS** validate dependencies before committing
- **ALWAYS** use interfaces for cross-layer communication
- **ALWAYS** document component dependencies
- **ALWAYS** refactor when circular dependencies are detected
- **ALWAYS** keep dependency graph shallow (avoid deep nesting)

### DON'Ts ‚ùå

- **NEVER** create circular dependencies
- **NEVER** allow lower layers to depend on higher layers
- **NEVER** create tight coupling between components
- **NEVER** skip dependency validation
- **NEVER** mix concerns across layers
- **NEVER** create bidirectional dependencies

## Dependency Documentation

### Documenting Dependencies

**In code:**
```typescript
// Component: UserService
// Dependencies:
//   - UserRepository (Core layer)
//   - Logger (Foundation layer)
//   - Config (Foundation layer)
// Does NOT depend on:
//   - UserController (Presentation layer)
//   - UserAPI (Presentation layer)
```

**In documentation:**
- Maintain `docs/DAG.md` with component dependency graph
- Update when adding new components
- Include dependency direction and purpose

## Refactoring Circular Dependencies

### When Circular Dependency is Detected

1. **Identify the cycle**: Map the dependency chain
2. **Find common dependency**: Extract shared functionality
3. **Introduce interface**: Use dependency inversion
4. **Restructure layers**: Move components to appropriate layer
5. **Validate fix**: Run dependency check again

### Example Refactoring

**Before (Circular):**
```
Feature A ‚Üí Feature B ‚Üí Feature A
```

**After (Fixed):**
```
Core
  ‚îî‚îÄ‚îÄ SharedService

Feature A ‚Üí Core
Feature B ‚Üí Core
```

## Integration with AGENT_AUTOMATION

**CRITICAL**: Include dependency validation in AGENT_AUTOMATION workflow:

```bash
# Step 1.5: Dependency Validation (before implementation)
# Check for circular dependencies
npm run check-deps  # or equivalent for your language

# If circular dependencies detected:
# ‚ùå STOP - Fix architecture first
# ‚úÖ Refactor to remove cycles
# ‚úÖ Re-validate before proceeding
```

## Language-Specific Guidelines

### TypeScript/JavaScript
- Use `madge` or `dependency-cruiser` for validation
- Configure ESLint rules for import ordering
- Use path aliases to enforce layer structure

### Rust
- Cargo automatically detects circular dependencies
- Use `cargo tree` to visualize dependencies
- Organize modules to reflect layer structure

### Python
- Use `pylint` or `vulture` for import analysis
- Organize packages to reflect layer structure
- Use `__init__.py` to control exports

### Go
- Use `go vet` for dependency validation
- Organize packages in directories reflecting layers
- Use interfaces to decouple components

## Examples

### Good Architecture ‚úÖ

```
src/
‚îú‚îÄ‚îÄ foundation/
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ types/
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ repositories/
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (depends on core, foundation)
‚îÇ   ‚îî‚îÄ‚îÄ payments/
‚îÇ       ‚îî‚îÄ‚îÄ (depends on core, foundation)
‚îî‚îÄ‚îÄ presentation/
    ‚îú‚îÄ‚îÄ cli/
    ‚îÇ   ‚îî‚îÄ‚îÄ (depends on features, core, foundation)
    ‚îî‚îÄ‚îÄ api/
        ‚îî‚îÄ‚îÄ (depends on features, core, foundation)
```

### Bad Architecture ‚ùå

```
src/
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îî‚îÄ‚îÄ auth/
‚îÇ       ‚îî‚îÄ‚îÄ (depends on presentation)  # ‚ùå Wrong direction
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ (depends on features)  # ‚ùå Wrong direction
‚îî‚îÄ‚îÄ presentation/
    ‚îî‚îÄ‚îÄ (depends on foundation only)  # ‚ùå Missing dependencies
```

## Maintenance

### Regular Checks

- **Before every commit**: Run dependency validation
- **Weekly**: Review dependency graph for optimization
- **Before major refactoring**: Document current dependencies
- **After adding new components**: Update DAG documentation

### Tools Integration

Add dependency checks to:
- Pre-commit hooks
- CI/CD pipelines
- AGENT_AUTOMATION workflow
- Quality gates

<!-- DAG:END -->


<!-- RULEBOOK:SKILL:core/dag:END -->

<!-- RULEBOOK:SKILL:core/documentation-rules:START -->
# Documentation Standards

**CRITICAL**: All documentation in English. Root README concise, detailed docs in `/docs`.

## Structure

**Root-Level (ONLY):**
- `README.md` - Overview + quick start
- `CHANGELOG.md` - Version history
- `AGENTS.md` - AI instructions
- `LICENSE`, `CONTRIBUTING.md`, `SECURITY.md`

**All Other Docs in `/docs`:**
- `ARCHITECTURE.md`, `DEVELOPMENT.md`, `ROADMAP.md`
- `specs/`, `guides/`, `diagrams/`, `benchmarks/`

## Update Requirements by Commit Type

| Type | Update |
|------|--------|
| `feat` | README features, API docs, CHANGELOG "Added" |
| `fix` | Troubleshooting, CHANGELOG "Fixed" |
| `breaking` | CHANGELOG + migration guide, version docs |
| `perf` | Benchmarks, CHANGELOG "Performance" |
| `security` | SECURITY.md, CHANGELOG "Security" |
| `docs` | Verify spelling/links only |
| `refactor` | Update if behavior changed |

## Quality Checks (CI/CD)

```bash
markdownlint **/*.md         # Lint markdown
markdown-link-check **/*.md  # Check links
codespell **/*.md            # Spell check
```

**MUST pass before commit** (see AGENT_AUTOMATION).
<!-- RULEBOOK:SKILL:core/documentation-rules:END -->

<!-- RULEBOOK:SKILL:core/quality-enforcement:START -->
<!-- QUALITY_ENFORCEMENT:START -->
# Quality Enforcement Rules

**CRITICAL**: These rules are NON-NEGOTIABLE and MUST be followed without exception.

## Absolute Prohibitions

### Test Bypassing - STRICTLY FORBIDDEN
- NEVER use .skip(), .only(), or .todo() to bypass failing tests
- NEVER comment out failing tests
- NEVER use @ts-ignore, @ts-expect-error, or similar to hide test errors
- NEVER mock/stub functionality just to make tests pass without fixing root cause
- FIX the actual problem causing test failures

### Git Hook Bypassing - STRICTLY FORBIDDEN  
- NEVER use --no-verify flag on git commit
- NEVER use --no-verify flag on git push
- NEVER disable or skip pre-commit hooks
- NEVER disable or skip pre-push hooks
- FIX the issues that hooks are detecting

### Test Implementation - STRICTLY FORBIDDEN
- NEVER create boilerplate tests that don't actually test behavior
- NEVER write tests that always pass regardless of implementation
- NEVER write tests without assertions
- NEVER mock everything to avoid testing real behavior
- WRITE meaningful tests that verify actual functionality

### Problem Solving Approach - REQUIRED
- DO NOT seek the simplest bypass or workaround
- DO NOT be creative with shortcuts that compromise quality
- DO solve problems properly following best practices
- DO use proven, established solutions from decades of experience
- DO fix root causes, not symptoms

### Temporary Files and Scripts - STRICTLY FORBIDDEN
- **NEVER** create temporary files in project root or any directory outside `/scripts`
- **NEVER** create test files, log files, or debug files outside `/scripts`
- **NEVER** leave temporary files after use - they MUST be deleted immediately
- **ALWAYS** create all scripts inside `/scripts` directory
- **ALWAYS** remove temporary files immediately after use (MANDATORY)
- **ALWAYS** clean up test artifacts, log files, and debug files before committing
- **ALWAYS** use `/scripts` directory for any temporary scripts or test files

**Why This Matters:**
LLM assistants often create temporary files for testing but forget to remove them, accumulating dozens of junk files that pollute the repository. All temporary work MUST be done in `/scripts` and cleaned up immediately.

**Examples:**
- ‚ùå Creating `test.js`, `debug.log`, `temp.json` in project root
- ‚ùå Leaving test files after debugging
- ‚ùå Creating scripts outside `/scripts` directory
- ‚úÖ Creating `/scripts/test-feature.js` and removing it after use
- ‚úÖ Using `/scripts` for all temporary work
- ‚úÖ Cleaning up all temporary files before committing

## Enforcement

These rules apply to ALL implementations:
- Bug fixes
- New features  
- Refactoring
- Documentation changes
- Any code modifications

**Violation = Implementation Rejected**

<!-- QUALITY_ENFORCEMENT:END -->


<!-- RULEBOOK:SKILL:core/quality-enforcement:END -->

<!-- RULEBOOK:SKILL:core/ralph:START -->
<!-- RALPH:START -->
# Ralph Autonomous Loop Integration

Ralph is an autonomous AI agent loop that iteratively solves tasks with fresh context for each iteration. This document explains how to use Ralph with your Rulebook project.

## Overview

Ralph enables:
- **Autonomous Multi-Iteration Development**: AI agents solve tasks across multiple iterations
- **Quality Gates**: Automatic checks for type-safety, linting, testing, and coverage
- **Progress Tracking**: Detailed history of each iteration with metrics and learnings
- **Fresh Context per Iteration**: Each iteration starts with clean context, avoiding context window exhaustion
- **Graceful Interruption**: Pause and resume capabilities for long-running tasks

## Quick Start

### Initialize Ralph
```bash
rulebook ralph init
```
This creates:
- `.rulebook/ralph/prd.json` - Product Requirements Document from rulebook tasks
- `.rulebook/ralph/state.json` - Current loop state and progress
- `.rulebook/ralph/history/` - Per-iteration metadata and results

### Run Ralph Loop
```bash
rulebook ralph run --max-iterations 10 --tool claude
```
Flags:
- `--max-iterations N` - Maximum iterations before stopping (default: 10)
- `--tool TOOL` - AI tool to use: `claude`, `amp`, or `gemini` (default: claude)

### Check Status
```bash
rulebook ralph status
```
Shows:
- Current iteration count
- Completed vs. pending tasks
- Success rate and quality metrics

### View History
```bash
rulebook ralph history --limit 5
```
Displays:
- Last 5 iterations with status and duration
- Task completions and failures
- Quality gate results

### Pause/Resume
```bash
rulebook ralph pause    # Gracefully pause the loop
rulebook ralph resume   # Continue from where it paused
```

## How Ralph Works

### Iteration Loop
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Load Next Pending Task from PRD      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 2. Execute Agent with Task Context      ‚îÇ
‚îÇ    - Fresh context per iteration        ‚îÇ
‚îÇ    - Task description and acceptance    ‚îÇ
‚îÇ      criteria from rulebook             ‚îÇ
‚îÇ    - Previous iteration learnings       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 3. Parse Agent Output                   ‚îÇ
‚îÇ    - Extract quality gate results       ‚îÇ
‚îÇ    - Extract learnings and errors       ‚îÇ
‚îÇ    - Extract git commit hash            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 4. Record Iteration Results             ‚îÇ
‚îÇ    - Save to history/.iteration-N.json  ‚îÇ
‚îÇ    - Update task status in PRD          ‚îÇ
‚îÇ    - Log progress to progress.txt       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 5. Check Loop Continuation              ‚îÇ
‚îÇ    - All tasks completed?    ‚Üí Stop     ‚îÇ
‚îÇ    - Max iterations reached? ‚Üí Stop     ‚îÇ
‚îÇ    - Otherwise              ‚Üí Loop      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Quality Gates
Ralph automatically checks these gates after each iteration:

| Gate | Description | Pass Criteria |
|------|-------------|---------------|
| **type-check** | TypeScript compilation | No errors |
| **lint** | ESLint code quality | No errors |
| **tests** | Unit tests | All passing |
| **coverage** | Code coverage | ‚â•95% |

**Iteration Status:**
- ‚úÖ **success** - All 4 gates pass
- ‚ö†Ô∏è **partial** - 2-3 gates pass
- ‚ùå **failed** - 0-1 gates pass

### Fresh Context Strategy
Each iteration provides context to the agent:
1. **Task Description** - What to implement
2. **Acceptance Criteria** - How to verify success
3. **Quality Requirements** - Type-check, lint, tests, coverage
4. **Previous Learnings** - Lessons from prior iterations
5. **Project Context** - Recent git commits, file structure
6. **Git Status** - Current diff and uncommitted changes

This allows agents to make progress without exhausting context window.

## Task Sizing for Ralph

### Good Task Sizes
‚úÖ **Small Tasks** (1-2 iterations)
- Add single feature (button, form field)
- Fix localized bug
- Refactor single function/component
- Add utility function

Example:
```markdown
## Task: Add Dark Mode Toggle

What Changes: Add UI toggle for theme switching

Acceptance Criteria:
- [ ] Toggle button visible in settings
- [ ] Click toggles theme immediately
- [ ] Selection persists in localStorage
- [ ] All tests passing
```

‚úÖ **Medium Tasks** (3-5 iterations)
- Implement new API endpoint
- Refactor component with dependencies
- Add authentication system
- Build complex feature with multiple parts

Example:
```markdown
## Task: Implement User Authentication

What Changes: Add JWT-based user auth

Acceptance Criteria:
- [ ] Login endpoint working
- [ ] Token generation and validation
- [ ] Protected routes enforced
- [ ] Refresh token rotation
- [ ] Error handling comprehensive
```

### Poor Task Sizes
‚ùå **Too Large** (>5 iterations)
- Build entire new module
- Major architectural redesign
- Complete feature system

‚Üí Break into smaller, focused tasks

‚ùå **Too Vague** (unclear acceptance criteria)
- "Improve performance"
- "Make code better"
- "Add tests"

‚Üí Define specific, measurable criteria

## Configuration

### .rulebook File
```json
{
  "ralph": {
    "enabled": true,
    "maxIterations": 10,
    "tool": "claude",
    "maxContextLoss": 3
  }
}
```

| Setting | Default | Description |
|---------|---------|-------------|
| `enabled` | `true` | Enable Ralph features |
| `maxIterations` | `10` | Max iterations per run |
| `tool` | `claude` | Default AI tool |
| `maxContextLoss` | `3` | Allow 3 context loss events before stopping |

## MCP Integration

Ralph provides 4 MCP tools for programmatic access:

### rulebook_ralph_init
Initialize Ralph and generate PRD from tasks
```json
{
  "type": "resource",
  "name": "rulebook_ralph_init",
  "description": "Initialize Ralph autonomous loop"
}
```

### rulebook_ralph_run
Execute autonomous iteration loop
```json
{
  "type": "resource",
  "name": "rulebook_ralph_run",
  "description": "Run Ralph iteration loop"
}
```

### rulebook_ralph_status
Get current loop state and progress
```json
{
  "type": "resource",
  "name": "rulebook_ralph_status",
  "description": "Get Ralph loop status"
}
```

### rulebook_ralph_get_iteration_history
Retrieve iteration metadata and statistics
```json
{
  "type": "resource",
  "name": "rulebook_ralph_get_iteration_history",
  "description": "Get Ralph iteration history"
}
```

## Directory Structure

Ralph stores all data in `.rulebook/ralph/`:
```
.rulebook/ralph/
‚îú‚îÄ‚îÄ prd.json              # Product Requirements Document
‚îú‚îÄ‚îÄ state.json            # Current loop state
‚îú‚îÄ‚îÄ progress.txt          # Append-only progress log
‚îî‚îÄ‚îÄ history/
    ‚îú‚îÄ‚îÄ iteration-1.json  # Metadata from iteration 1
    ‚îú‚îÄ‚îÄ iteration-2.json  # Metadata from iteration 2
    ‚îî‚îÄ‚îÄ ...
```

### prd.json Structure
```json
{
  "version": "1.0",
  "generated_at": "2026-02-26T12:00:00Z",
  "project_name": "my-project",
  "total_tasks": 5,
  "tasks": [
    {
      "id": "task-1",
      "title": "Task Title",
      "description": "Task description",
      "status": "pending|in_iteration|completed|blocked",
      "priority": 1,
      "acceptance_criteria": ["Criterion 1", "Criterion 2"],
      "estimated_iterations": 2,
      "created_at": "2026-02-26T12:00:00Z",
      "updated_at": "2026-02-26T12:00:00Z"
    }
  ]
}
```

### iteration-N.json Structure
```json
{
  "iteration": 1,
  "started_at": "2026-02-26T12:00:00Z",
  "completed_at": "2026-02-26T12:05:00Z",
  "task_id": "task-1",
  "task_title": "Task Title",
  "duration_ms": 300000,
  "status": "success|partial|failed",
  "git_commit": "abc1234",
  "quality_checks": {
    "type_check": true,
    "lint": true,
    "tests": true,
    "coverage_met": true
  }
}
```

## Best Practices

### 1. Clear Acceptance Criteria
‚ùå Bad: "Make it work"
‚úÖ Good: "User can click button and see modal dialog with form"

### 2. Limit to 1 Task per Run
Run Ralph on single focused task for best results
```bash
# Focus on one task at a time
rulebook ralph run --max-iterations 5
```

### 3. Review Iteration Results
Check quality gates and learnings between runs
```bash
rulebook ralph history --limit 1  # See latest iteration
```

### 4. Break Large Features
Don't try to implement entire systems in one run
- Task 1: API endpoint with basic validation
- Task 2: Database models and migrations
- Task 3: Error handling and edge cases
- Task 4: Tests and documentation

### 5. Inspect Failed Iterations
If status is "failed", examine what went wrong:
```bash
cat .rulebook/ralph/history/iteration-N.json
cat .rulebook/ralph/progress.txt
```

### 6. Use Learnings from History
Ralph extracts and stores learnings from iterations. Review these to understand what strategies worked.

## Troubleshooting

### Iteration Loop Stops Early
**Cause**: Hit max iterations or all tasks completed

**Solution**:
- Check status: `rulebook ralph status`
- View history: `rulebook ralph history`
- Increase max iterations: `rulebook ralph run --max-iterations 20`

### Quality Gates Failing
**Cause**: Type-check, lint, tests, or coverage not meeting standards

**Solution**:
- Review failing gate in iteration history
- Check PRD acceptance criteria match quality gates
- Ensure task is small enough for single iteration

### Context Loss Events
**Cause**: Agent ran out of context window during iteration

**Solution**:
- Break task into smaller pieces
- Reduce task description complexity
- Increase agent context window if possible

### Ralph State Gets Stuck
**Cause**: Invalid state.json or corrupted PRD

**Solution**:
```bash
rm .rulebook/ralph/state.json      # Reset state
rulebook ralph init                # Regenerate PRD
rulebook ralph run                 # Restart loop
```

## Examples

### Example 1: Simple Feature Implementation
Task: Add dark mode toggle button

```bash
# Initialize Ralph
rulebook ralph init

# Run for up to 3 iterations
rulebook ralph run --max-iterations 3

# Check results
rulebook ralph history

# Review final output
cat .rulebook/ralph/history/iteration-*.json
```

### Example 2: Multiple Task Execution
Tasks: Several small features to implement

```bash
# Run multiple tasks with generous iteration limit
rulebook ralph run --max-iterations 20

# Monitor progress
watch -n 5 'rulebook ralph status'

# Pause if needed
rulebook ralph pause

# Review and resume
rulebook ralph history
rulebook ralph resume
```

### Example 3: Debugging Failed Iteration
```bash
# Run into failure
rulebook ralph run --max-iterations 3

# See what failed
cat .rulebook/ralph/history/iteration-3.json

# View full progress log
tail -50 .rulebook/ralph/progress.txt

# Manual fix and resume
rulebook ralph resume
```

## Limitations

- **Single Sequential Loop**: Ralph processes one task at a time sequentially
- **No Parallel Execution**: Tasks don't run in parallel (by design)
- **No Task Dependencies**: No automatic dependency resolution between tasks
- **Manual Task Ordering**: You order tasks by priority in PRD

## Related Documentation

- See `/.rulebook/specs/RULEBOOK.md` for task structure
- See `/.rulebook/specs/QUALITY_ENFORCEMENT.md` for quality gates
- See `/rulebook/AGENTS.md` for AI agent integration

<!-- RALPH:END -->

<!-- RULEBOOK:SKILL:core/ralph:END -->

<!-- RULEBOOK:SKILL:core/rulebook:START -->
<!-- RULEBOOK:START -->
# Rulebook Task Management

**CRITICAL**: Use Rulebook's built-in task management system for spec-driven development of new features and breaking changes.

## When to Use

Create tasks for:
- ‚úÖ New features/capabilities
- ‚úÖ Breaking changes
- ‚úÖ Architecture changes
- ‚úÖ Performance/security work

Skip for:
- ‚ùå Bug fixes (restore intended behavior)
- ‚ùå Typos, formatting, comments
- ‚ùå Dependency updates (non-breaking)

## Persistent Memory Integration

**IMPORTANT**: Task management is tightly integrated with persistent memory system for cross-session context:

### Task Completion and Memory
When a task is marked as completed:
1. **Auto-save to memory** (if enabled): Key learnings, patterns, gotchas from task specs are captured
2. **Search past tasks**: Before creating similar tasks, search memory for past implementations:
   ```bash
   rulebook memory search "authentication" --type feature
   ```
3. **Update implementation faster**: Reference past solutions documented in memory

### Memory during Task Development
As you work on a task:
- **Save discoveries**: Use `rulebook memory save` to capture patterns and gotchas
- **Reference past context**: Search memory for related implementations
- **Document decisions**: Save architectural choices for future developers

## ‚ö†Ô∏è CRITICAL: Task Creation is MANDATORY Before Implementation

**ABSOLUTE RULE**: You MUST create a task BEFORE implementing ANY feature.

### Why This Matters

**Without task registration:**
- ‚ùå Tasks can be lost in context
- ‚ùå No tracking of implementation progress
- ‚ùå No record of what was done and why
- ‚ùå Difficult to resume work after context loss
- ‚ùå No validation of completion criteria

**With task registration:**
- ‚úÖ All features are tracked and documented
- ‚úÖ Progress is visible and measurable
- ‚úÖ Implementation history is preserved
- ‚úÖ Easy to resume work from any point
- ‚úÖ Clear completion criteria

### MANDATORY Workflow

**NEVER start implementation without creating a task first:**

```bash
# ‚ùå WRONG: Starting implementation directly
# ... writing code without task ...

# ‚úÖ CORRECT: Create task first
rulebook task create <task-id>
# Write proposal.md
# Write tasks.md
# Write spec deltas
rulebook task validate <task-id>
# NOW you can start implementation
```

### Task Creation Before Any Feature Request

**When a feature is requested:**

1. **STOP** - Do not start coding
2. **Create task** - `rulebook task create <task-id>`
3. **Plan** - Write proposal.md and tasks.md
4. **Spec** - Write spec deltas
5. **Validate** - `rulebook task validate <task-id>`
6. **THEN** - Start implementation

**Example:**
```
User: "Add user authentication feature"

‚ùå WRONG: Start coding immediately
‚úÖ CORRECT:
  1. rulebook task create add-user-authentication
  2. Write proposal.md explaining why and what
  3. Write tasks.md with implementation checklist
  4. Write specs/core/spec.md with requirements
  5. rulebook task validate add-user-authentication
  6. NOW start implementing
```

## CRITICAL: Task Creation Workflow

**MANDATORY STEPS** - Follow in this exact order:

### Step 1: Check Context7 MCP (MANDATORY)

**BEFORE creating ANY task, you MUST:**

1. **Query Context7 for OpenSpec documentation** (Rulebook uses OpenSpec-compatible format):
   ```
   @Context7 /fission-ai/openspec task creation format spec structure
   ```

2. **Review official format requirements**:
   - Spec delta file format
   - Requirement structure
   - Scenario formatting
   - Delta headers (ADDED/MODIFIED/REMOVED/RENAMED)

3. **Verify format requirements**:
   - Scenario MUST use `#### Scenario:` (4 hashtags, NOT 3, NOT bullets)
   - Requirements MUST use `### Requirement: [Name]`
   - MUST include SHALL/MUST statement after requirement name
   - MUST include at least one scenario per requirement
   - Purpose section MUST have minimum 20 characters

**Why This Matters:**
Most AI assistants create tasks with incorrect formats (wrong scenario headers, missing SHALL statements, incomplete deltas). Context7 provides the official format documentation that prevents validation failures.

### Step 2: Explore Current State

```bash
# List existing tasks
rulebook task list

# List active changes
rulebook task list --active

# View task details
rulebook task show <task-id>
```

### Step 3: Choose Task ID

- Use **verb-led** kebab-case: `add-auth`, `update-api`, `remove-feature`, `refactor-module`
- Must be unique (check existing tasks)
- Descriptive and focused (one capability per task)

### Step 4: Create Task Structure

```bash
# Create new task
rulebook task create <task-id>

# This creates:
# /.rulebook/tasks/<task-id>/
#   ‚îú‚îÄ‚îÄ proposal.md       # Why and what changes
#   ‚îú‚îÄ‚îÄ tasks.md          # Implementation checklist
#   ‚îú‚îÄ‚îÄ design.md         # Technical decisions (optional)
#   ‚îî‚îÄ‚îÄ specs/
#       ‚îî‚îÄ‚îÄ <module>/
#           ‚îî‚îÄ‚îÄ spec.md   # Delta showing additions/modifications
```

### Step 5: Write Proposal

**File**: `/.rulebook/tasks/<task-id>/proposal.md`

```markdown
# Proposal: Task Name

## Why
Minimum 20 characters explaining why this change is needed.
Provide context, motivation, and business/technical rationale.

## What Changes
Detailed description of what will change:
- Specific components affected
- New features or capabilities
- Breaking changes (if any)
- Migration path (if applicable)

## Impact
- Affected specs: list spec names
- Affected code: list files/modules
- Breaking change: YES/NO
- User benefit: describe benefits
```

### Step 6: Write Tasks Checklist

**File**: `/.rulebook/tasks/<task-id>/tasks.md`

```markdown
## 1. Implementation Phase
- [ ] 1.1 First task item
- [ ] 1.2 Second task item

## 2. Testing Phase
- [ ] 2.1 Write unit tests
- [ ] 2.2 Write integration tests

## 3. Documentation Phase
- [ ] 3.1 Update README
- [ ] 3.2 Update CHANGELOG
```

### Step 7: Write Spec Delta

**File**: `/.rulebook/tasks/<task-id>/specs/<module>/spec.md`

**CRITICAL FORMAT REQUIREMENTS:**

```markdown
# Specification Name

## ADDED Requirements

### Requirement: Feature Name
The system SHALL/MUST do something specific and testable.
Every requirement needs SHALL or MUST keyword.

#### Scenario: Scenario Name
Given some precondition
When an action occurs
Then an expected outcome happens

## MODIFIED Requirements

### Requirement: Existing Feature
The system SHALL/MUST do something modified.

#### Scenario: Modified scenario
Given updated precondition
When action occurs
Then new expected outcome

## REMOVED Requirements

### Requirement: Deprecated Feature
[Description of what is being removed]

## RENAMED Requirements
- FROM: `### Requirement: Old Name`
- TO: `### Requirement: New Name`
```

**Format Rules:**
- ‚úÖ Purpose section: Minimum 20 characters
- ‚úÖ Requirements: Must contain SHALL or MUST
- ‚úÖ Scenarios: Use `#### Scenario:` (4 hashtags)
- ‚úÖ Scenarios: Use Given/When/Then structure
- ‚úÖ Deltas: Use ADDED/MODIFIED/REMOVED/RENAMED headers
- ‚ùå NEVER use 3 hashtags for scenarios
- ‚ùå NEVER use bullet points for scenarios
- ‚ùå NEVER omit SHALL/MUST from requirements

### Step 8: Validate Task

```bash
# Validate task format
rulebook task validate <task-id>

# Validate with strict mode (recommended)
rulebook task validate <task-id> --strict

# Validate all tasks
rulebook task validate --all
```

**Validation checks:**
- Purpose section length (‚â•20 chars)
- Requirement keywords (SHALL/MUST)
- Scenario format (4 hashtags)
- Given/When/Then structure
- Delta headers format

### Step 9: Update Task Status

```bash
# Mark task as in progress
rulebook task update <task-id> --status in-progress

# Update task progress
rulebook task update <task-id> --progress 50

# Mark task as completed
rulebook task update <task-id> --status completed
```

### Step 10: Archive Completed Task

```bash
# Archive completed task
rulebook task archive <task-id>

# Archive without prompts
rulebook task archive <task-id> --yes
```

**Archive process:**
1. Validates task format
2. Checks task completion status
3. Applies spec deltas to main specifications
4. Moves task to `/.rulebook/tasks/archive/YYYY-MM-DD-<task-id>/`
5. Updates related specifications

## Task Format Examples

### Correct Format ‚úÖ

```markdown
# Auth Specification

## ADDED Requirements

### Requirement: Two-Factor Authentication
The system MUST require a second factor during login for enhanced security.

#### Scenario: OTP required
Given a user submits valid credentials
When authentication starts
Then an OTP challenge is required

#### Scenario: OTP verification
Given a user receives an OTP code
When they submit the correct OTP
Then they are authenticated successfully
```

### Incorrect Format ‚ùå

```markdown
# Auth Specification

## Requirements

### Requirement: Two-Factor Authentication
The system requires a second factor.  # ‚ùå Missing SHALL/MUST

#### Scenario: OTP required  # ‚ùå Only 3 hashtags
- WHEN user submits credentials  # ‚ùå Using bullets instead of Given/When/Then
- THEN OTP challenge is required
```

## Common Pitfalls & How to Avoid Them

### Top 5 Mistakes AI Assistants Make

1. **Wrong Scenario Headers**
   - ‚ùå `### Scenario:` (3 hashtags)
   - ‚úÖ `#### Scenario:` (4 hashtags)

2. **Missing SHALL/MUST Keywords**
   - ‚ùå "The system provides authentication"
   - ‚úÖ "The system SHALL provide authentication"

3. **Using Bullets for Scenarios**
   - ‚ùå `- WHEN user does X THEN Y happens`
   - ‚úÖ `Given X\nWhen Y\nThen Z`

4. **Incomplete Purpose Section**
   - ‚ùå "Auth system" (too short)
   - ‚úÖ "Authentication system for secure user access with JWT tokens and session management" (‚â•20 chars)

5. **Wrong Delta Headers**
   - ‚ùå `## New Requirements` or `## Changes`
   - ‚úÖ `## ADDED Requirements`, `## MODIFIED Requirements`, etc.

## Integration with AGENT_AUTOMATION

**CRITICAL**: After implementing a task, follow AGENT_AUTOMATION workflow:

1. Run quality checks (lint, test, type-check, build)
2. Update task status in `tasks.md`
3. Update documentation (ROADMAP, CHANGELOG, specs)
4. Commit with conventional commit format
5. Archive task when complete

## ‚ö†Ô∏è CRITICAL: Git Hooks Will Block Commits with Problems

**ABSOLUTE RULE**: Pre-commit and pre-push hooks will **BLOCK** any commit attempt if there are:
- ‚ùå Lint errors or warnings
- ‚ùå Test failures
- ‚ùå Type check errors
- ‚ùå Formatting issues
- ‚ùå Coverage below thresholds

### Why This Matters

**DO NOT attempt to commit code with problems:**
- ‚ùå `git commit` will **FAIL** if lint has errors
- ‚ùå `git commit` will **FAIL** if tests are failing
- ‚ùå `git push` will **FAIL** if pre-push checks fail
- ‚ùå You will waste time trying to commit broken code
- ‚ùå The hooks will reject your commit automatically

**ALWAYS fix problems BEFORE attempting to commit:**
- ‚úÖ Run `npm run lint` and fix ALL errors/warnings first
- ‚úÖ Run `npm test` and ensure ALL tests pass
- ‚úÖ Run `npm run type-check` and fix ALL type errors
- ‚úÖ Run `npm run format` if formatting is required
- ‚úÖ Run `npm test -- --coverage` and ensure coverage thresholds are met
- ‚úÖ **ONLY THEN** attempt `git commit`

### Mandatory Pre-Commit Workflow

**BEFORE every commit, you MUST:**

```bash
# 1. Fix lint errors FIRST (highest priority)
npm run lint
# Fix ALL errors and warnings
# If lint fails, commit will be blocked

# 2. Fix test failures SECOND
npm test
# Fix ALL failing tests
# If tests fail, commit will be blocked

# 3. Fix type errors THIRD
npm run type-check
# Fix ALL type errors
# If type check fails, commit will be blocked

# 4. Fix formatting (if required)
npm run format
# Apply formatting fixes

# 5. Verify coverage (if required by hooks)
npm test -- --coverage
# Ensure coverage thresholds are met

# 6. ONLY AFTER all checks pass, attempt commit
git add .
git commit -m "feat: your commit message"
# This will now succeed because all checks passed
```

### What Happens If You Try to Commit with Problems

**Example of blocked commit:**

```bash
$ git commit -m "feat: add new feature"

üîç Running TypeScript/JavaScript pre-commit checks...
  ‚Üí Type checking...
  ‚Üí Linting...

/mnt/f/project/src/feature.ts
   42:19  error  Unexpected any. Specify a different type  @typescript-eslint/no-explicit-any

‚úñ 1 problem (1 error, 0 warnings)

‚ùå Commit blocked: Lint errors found
```

**You MUST fix the error before committing:**

```bash
# Fix the lint error
# ... edit code to fix the issue ...

# Run lint again to verify
npm run lint
# ‚úÖ All checks pass

# NOW commit will succeed
git commit -m "feat: add new feature"
# ‚úÖ Commit successful
```

### ‚ö†Ô∏è CRITICAL: NEVER Use --no-verify to Bypass Hooks

**ABSOLUTE PROHIBITION**: You MUST NEVER use `--no-verify` or `--no-gpg-sign` flags to bypass git hooks.

**FORBIDDEN COMMANDS:**
- ‚ùå `git commit --no-verify` - **NEVER USE THIS**
- ‚ùå `git commit -n` - **NEVER USE THIS** (short form of --no-verify)
- ‚ùå `git push --no-verify` - **NEVER USE THIS**
- ‚ùå Any flag that skips pre-commit or pre-push hooks

### Why This Is Prohibited

**Using `--no-verify` defeats the entire purpose of quality gates:**
- ‚ùå Allows broken code to be committed
- ‚ùå Bypasses all quality checks (lint, test, type-check)
- ‚ùå Introduces technical debt and bugs
- ‚ùå Violates project quality standards
- ‚ùå Can break the build for other developers
- ‚ùå Makes code review harder (reviewers see broken code)

**The hooks exist for a reason:**
- ‚úÖ They protect code quality
- ‚úÖ They prevent bugs from entering the codebase
- ‚úÖ They ensure consistency across the project
- ‚úÖ They catch errors before they reach production

### What to Do Instead

**If you're tempted to use `--no-verify`, it means:**
1. **You have problems that need fixing** - Fix them first
2. **You're trying to commit too early** - Complete the work properly
3. **You're rushing** - Slow down and do it right

**Correct approach:**

```bash
# ‚ùå WRONG: Trying to bypass hooks
git commit --no-verify -m "feat: add feature"
# This is FORBIDDEN - never do this

# ‚úÖ CORRECT: Fix problems first, then commit
npm run lint
# Fix all errors...

npm test
# Fix all failing tests...

npm run type-check
# Fix all type errors...

# NOW commit (hooks will pass)
git commit -m "feat: add feature"
# ‚úÖ Commit successful - all checks passed
```

### Summary

**CRITICAL RULES:**
- ‚ö†Ô∏è **NEVER** attempt to commit code with lint errors - hooks will block it
- ‚ö†Ô∏è **NEVER** attempt to commit code with test failures - hooks will block it
- ‚ö†Ô∏è **NEVER** attempt to commit code with type errors - hooks will block it
- ‚ö†Ô∏è **NEVER** use `--no-verify` or any flag to bypass hooks - **ABSOLUTELY FORBIDDEN**
- ‚ö†Ô∏è **ALWAYS** fix ALL problems BEFORE attempting to commit
- ‚ö†Ô∏è **ALWAYS** run quality checks manually before `git commit`
- ‚ö†Ô∏è **ALWAYS** ensure all checks pass before committing

**The hooks are there to protect code quality - they will NOT let broken code through. Always resolve problems first, then commit. Bypassing hooks is strictly prohibited and defeats the purpose of quality gates.**

## MANDATORY: Task List Updates During Implementation

**CRITICAL RULE**: You MUST update the task list (`tasks.md`) immediately after completing and testing each implementation step.

### When to Update Task List

**ALWAYS update `tasks.md` when:**
- ‚úÖ You complete a task item (mark as `[x]`)
- ‚úÖ You finish implementing a feature and it's tested
- ‚úÖ You complete a test suite
- ‚úÖ You finish documentation updates
- ‚úÖ You verify the implementation works correctly

**NEVER commit without updating `tasks.md` if you've made progress on a task.**

### How to Update Task List

1. **After Implementation**:
   ```markdown
   ## 1. Implementation Phase
   - [x] 1.1 Create task manager module  # ‚úÖ Mark as done
   - [x] 1.2 Add validation logic        # ‚úÖ Mark as done
   - [ ] 1.3 Add archive functionality   # Still pending
   ```

2. **After Testing**:
   ```markdown
   ## 2. Testing Phase
   - [x] 2.1 Write unit tests            # ‚úÖ Tests written and passing
   - [x] 2.2 Write integration tests     # ‚úÖ Tests written and passing
   - [ ] 2.3 Add E2E tests                # Still pending
   ```

3. **After Documentation**:
   ```markdown
   ## 3. Documentation Phase
   - [x] 3.1 Update README                # ‚úÖ Updated
   - [x] 3.2 Update CHANGELOG             # ‚úÖ Updated
   - [ ] 3.3 Update API docs              # Still pending
   ```

### Workflow: Implement ‚Üí Test ‚Üí Verify Coverage ‚Üí Update Tasks ‚Üí Commit ‚Üí Next Task

**MANDATORY SEQUENCE** for every implementation:

```bash
# 1. Implement the feature
# ... write code ...

# 2. Test the implementation
npm test
npm run lint
npm run type-check

# 3. Verify test coverage (CRITICAL)
npm test -- --coverage
# Check coverage thresholds are met
# Fix any coverage gaps before proceeding

# 4. Update tasks.md IMMEDIATELY after successful tests and coverage check
# Mark completed items as [x] in tasks.md
# Update task status if needed

# 5. Verify task status is updated before moving to next task
rulebook task show <task-id>
# Confirm status reflects current progress

# 6. Commit locally (BACKUP - do this frequently)
git add .
git commit -m "feat: implement task manager validation

- Complete task 1.2: Add validation logic
- All tests passing
- Coverage verified: 95%
- Updated tasks.md"

# 7. Keep remote repository updated (if configured)
# Check if remote is configured
git remote -v

# If remote exists, push regularly
git push origin <branch-name>

# If no remote configured, see setup instructions below

# 8. Only then proceed to next task
# Follow priority order (most critical first)
```

## ‚ö†Ô∏è CRITICAL: Frequent Local Commits for Backup

**ABSOLUTE RULE**: Commit locally frequently, even if just for backup purposes.

### Why Frequent Commits Matter

**Without frequent commits:**
- ‚ùå Risk of losing work if system crashes
- ‚ùå No recovery point if something goes wrong
- ‚ùå Difficult to revert to previous working state
- ‚ùå Lost context if session is interrupted

**With frequent commits:**
- ‚úÖ Work is backed up locally
- ‚úÖ Easy to recover from mistakes
- ‚úÖ Can revert to any previous state
- ‚úÖ Progress is preserved

### When to Commit Locally

**Commit locally whenever you:**
- ‚úÖ Complete a task item (even if not fully tested)
- ‚úÖ Finish implementing a feature (before full testing)
- ‚úÖ Fix a bug or issue
- ‚úÖ Update documentation
- ‚úÖ Make significant progress
- ‚úÖ Feel the need for a backup point
- ‚úÖ Are about to try something risky
- ‚úÖ Are switching to a different task

**Commit frequency:**
- **Minimum**: After completing each task item
- **Recommended**: Every 15-30 minutes of active work
- **Maximum**: As often as you feel necessary for safety

### Local Commit Workflow

```bash
# Quick local commit (backup)
git add .
git commit -m "wip: progress on task 1.2

- Implemented validation logic
- Still testing
- Backup commit"

# Or more descriptive
git add .
git commit -m "feat: add validation logic (WIP)

- Task 1.2 in progress
- Core validation implemented
- Tests pending
- Backup before continuing"
```

### Commit Message Format for Backup Commits

**For work-in-progress commits:**
```bash
git commit -m "wip: <brief description>

- What was done
- Current status
- Next steps"
```

**For completed task items:**
```bash
git commit -m "feat: <feature description>

- Complete task X.Y: <task name>
- All tests passing
- Coverage verified
- Updated tasks.md"
```

## ‚ö†Ô∏è CRITICAL: Keep Remote Repository Updated

**MANDATORY**: Keep your remote repository synchronized with local work.

### Check Remote Configuration

**First, check if remote is configured:**
```bash
git remote -v
```

**If you see output like:**
```
origin  https://github.com/user/repo.git (fetch)
origin  https://github.com/user/repo.git (push)
```
‚úÖ Remote is configured - proceed to push regularly

**If you see no output or error:**
‚ùå No remote configured - see setup instructions below

### Push to Remote Regularly

**After local commits, push to remote:**
```bash
# Push current branch
git push origin <branch-name>

# Or push current branch (if tracking is set)
git push

# Push with tags
git push --tags
```

**Recommended push frequency:**
- **Minimum**: After completing a task
- **Recommended**: After every 2-3 local commits
- **Maximum**: After every local commit (if working solo)

### Remote Repository Setup

**If no remote repository is configured:**

#### Option 1: GitHub (Recommended)

1. **Create repository on GitHub:**
   - Go to https://github.com/new
   - Create a new repository
   - **DO NOT** initialize with README, .gitignore, or license (if you already have local repo)

2. **Add remote and push:**
   ```bash
   # Add remote (replace with your repository URL)
   git remote add origin https://github.com/username/repo-name.git
   
   # Or using SSH
   git remote add origin git@github.com:username/repo-name.git
   
   # Push to remote
   git push -u origin main
   # Or 'master' if that's your default branch
   ```

3. **Verify:**
   ```bash
   git remote -v
   git push
   ```

**GitHub Setup Guide:**
- **Official Guide**: https://docs.github.com/en/get-started/quickstart/create-a-repo
- **Adding Remote**: https://docs.github.com/en/get-started/getting-started-with-git/managing-remote-repositories

#### Option 2: GitLab

1. **Create repository on GitLab:**
   - Go to https://gitlab.com/projects/new
   - Create a new project
   - **DO NOT** initialize with README (if you already have local repo)

2. **Add remote and push:**
   ```bash
   git remote add origin https://gitlab.com/username/repo-name.git
   git push -u origin main
   ```

**GitLab Setup Guide:**
- **Official Guide**: https://docs.gitlab.com/ee/gitlab-basics/create-project.html

#### Option 3: Bitbucket

1. **Create repository on Bitbucket:**
   - Go to https://bitbucket.org/repo/create
   - Create a new repository

2. **Add remote and push:**
   ```bash
   git remote add origin https://bitbucket.org/username/repo-name.git
   git push -u origin main
   ```

**Bitbucket Setup Guide:**
- **Official Guide**: https://support.atlassian.com/bitbucket-cloud/docs/create-a-git-repository/

#### Option 4: Self-Hosted Git Server

**If using self-hosted Git server:**
```bash
# Add remote
git remote add origin <your-git-server-url>

# Push
git push -u origin main
```

### Verify Remote is Working

**After setting up remote:**
```bash
# Check remote configuration
git remote -v

# Test push
git push origin main

# If successful, you'll see:
# "Enumerating objects: X, done."
# "Writing objects: 100% (X/X), done."
```

### Troubleshooting Remote Issues

**Error: "remote origin already exists"**
```bash
# Remove existing remote
git remote remove origin

# Add new remote
git remote add origin <new-url>
```

**Error: "authentication failed"**
- Check your credentials
- Use SSH keys for better security
- See: https://docs.github.com/en/authentication/connecting-to-github-with-ssh

**Error: "repository not found"**
- Verify repository URL is correct
- Check you have access to the repository
- Ensure repository exists on remote server

### Best Practices for Remote Sync

**DO's ‚úÖ:**
- ‚úÖ Push to remote after completing tasks
- ‚úÖ Push before switching branches
- ‚úÖ Push before trying risky changes
- ‚úÖ Push at end of work session
- ‚úÖ Use descriptive commit messages
- ‚úÖ Keep commits atomic (one logical change per commit)

**DON'Ts ‚ùå:**
- ‚ùå Don't push broken code (test first)
- ‚ùå Don't push sensitive information (API keys, passwords)
- ‚ùå Don't force push to shared branches
- ‚ùå Don't skip pushing for extended periods
- ‚ùå Don't commit without meaningful messages

### Automated Backup Reminder

**Set up reminders to push regularly:**
```bash
# Add to your shell profile (.bashrc, .zshrc, etc.)
alias git-backup='git add . && git commit -m "backup: $(date +%Y-%m-%d\ %H:%M:%S)" && git push'

# Use: git-backup (quick backup and push)
```

### Summary: Backup and Remote Sync Workflow

**Complete workflow:**
1. **Work locally** - Make changes
2. **Test changes** - Ensure they work
3. **Commit locally** - `git commit` (backup)
4. **Update tasks.md** - Mark progress
5. **Push to remote** - `git push` (if remote configured)
6. **Continue work** - Next task

**If no remote:**
1. **Set up remote** - Follow instructions above
2. **Push initial code** - `git push -u origin main`
3. **Continue regular pushes** - After each commit or task

### Priority Order: Most Critical First

**ALWAYS follow this priority order when continuing implementation:**

1. **Tests** (HIGHEST PRIORITY)
   - Write tests for the feature
   - Ensure all tests pass
   - Verify test coverage meets thresholds

2. **Coverage Verification** (CRITICAL)
   - Run coverage check: `npm test -- --coverage`
   - Fix any coverage gaps
   - Ensure coverage thresholds are met

3. **Update Task Status** (MANDATORY)
   - Mark completed items as `[x]` in `tasks.md`
   - Update task status if needed
   - Document what was completed

4. **Next Task** (Only after above steps)
   - Move to next most critical task
   - Follow same sequence

**Example Priority Order:**

```markdown
## Priority Order (Most Critical First)

### 1. Testing (CRITICAL - Do First)
- [ ] 1.1 Write unit tests for core functionality
- [ ] 1.2 Write integration tests
- [ ] 1.3 Verify test coverage ‚â• 95%

### 2. Coverage Verification (CRITICAL - Do Second)
- [ ] 2.1 Run coverage check
- [ ] 2.2 Fix coverage gaps
- [ ] 2.3 Verify thresholds met

### 3. Task Status Update (MANDATORY - Do Third)
- [ ] 3.1 Update tasks.md with completed items
- [ ] 3.2 Update task status
- [ ] 3.3 Document completion

### 4. Next Implementation (Only After Above)
- [ ] 4.1 Move to next critical task
- [ ] 4.2 Follow same sequence
```

### Never Skip Steps

**CRITICAL RULES:**
- ‚ùå NEVER proceed to next task without updating current task status
- ‚ùå NEVER skip test coverage verification
- ‚ùå NEVER mark tasks complete without tests passing
- ‚ùå NEVER implement without creating task first
- ‚úÖ ALWAYS update task status before moving to next task
- ‚úÖ ALWAYS verify coverage before marking task complete
- ‚úÖ ALWAYS follow priority order (most critical first)

### Task Status Tracking

**Track progress in `tasks.md`:**

```markdown
## Progress Summary
- Total tasks: 15
- Completed: 8
- In progress: 2
- Pending: 5
- Blocked: 0

## Current Status
- ‚úÖ Implementation Phase: 80% complete (4/5 tasks)
- ‚è≥ Testing Phase: 50% complete (2/4 tasks)
- ‚è∏Ô∏è Documentation Phase: 0% complete (0/3 tasks)
```

### Validation Before Committing

**BEFORE every commit, verify:**
- [ ] All completed tasks are marked as `[x]` in `tasks.md`
- [ ] Task status reflects current progress
- [ ] No tasks are marked complete without implementation
- [ ] All tests pass for completed tasks
- [ ] Test coverage meets thresholds (run `npm test -- --coverage`)
- [ ] Task status updated before moving to next task
- [ ] Documentation is updated for completed features

### Task Status Update Before Next Task

**CRITICAL RULE**: You MUST update task status in `tasks.md` BEFORE moving to the next task.

**Why:**
- Prevents loss of progress tracking
- Ensures context is preserved
- Makes it easy to resume work
- Provides clear progress visibility

**Workflow:**
```bash
# 1. Complete current task item
# ... implementation ...

# 2. Test and verify coverage
npm test
npm test -- --coverage

# 3. Update tasks.md IMMEDIATELY
# Mark as [x] and add status comment

# 4. Verify update
rulebook task show <task-id>
# Confirm status is updated

# 5. ONLY THEN proceed to next task
# Follow priority order (most critical first)
```

**Example:**
```markdown
## 1. Implementation Phase
- [x] 1.1 Create task manager module <!-- tested, coverage: 95% -->
- [x] 1.2 Add validation logic <!-- tested, coverage: 92%, status: complete -->
- [ ] 1.3 Add archive functionality <!-- next: will start after status update -->
```

## Task Archiving Workflow

**CRITICAL**: Archive tasks ONLY after full completion and validation.

### When to Archive

**Archive a task when:**
- ‚úÖ All items in `tasks.md` are marked as `[x]`
- ‚úÖ All tests pass (unit, integration, E2E)
- ‚úÖ Code review is complete (if applicable)
- ‚úÖ Documentation is updated (README, CHANGELOG, specs)
- ‚úÖ Task format is validated (`rulebook task validate <task-id>`)
- ‚úÖ Spec deltas have been applied to main specifications

**NEVER archive a task that is:**
- ‚ùå Partially complete
- ‚ùå Missing tests
- ‚ùå Failing validation
- ‚ùå Missing documentation

### Archive Process

**Step-by-step archive workflow:**

```bash
# 1. Verify all tasks are complete
rulebook task show <task-id>
# Check that all items in tasks.md are [x]

# 2. Run all quality checks
npm test
npm run lint
npm run type-check
npm run build

# 3. Validate task format
rulebook task validate <task-id>

# 4. Update final documentation
# - Update CHANGELOG.md
# - Update README.md if needed
# - Update any affected documentation

# 5. Archive the task
rulebook task archive <task-id>

# 6. Verify archive
rulebook task list --archived
# Task should appear in archived list
```

### Post-Archive Actions

**After archiving, ensure:**
- ‚úÖ Spec deltas are applied to main specifications
- ‚úÖ CHANGELOG.md is updated with the change
- ‚úÖ Any breaking changes are documented
- ‚úÖ Migration guides are created (if needed)
- ‚úÖ Related tasks are unblocked (if any)

### Archive Location

**Archived tasks are moved to:**
```
/.rulebook/tasks/archive/YYYY-MM-DD-<task-id>/
```

**Structure:**
```
/.rulebook/tasks/archive/2025-11-13-add-auth/
‚îú‚îÄ‚îÄ proposal.md
‚îú‚îÄ‚îÄ tasks.md          # All items marked [x]
‚îú‚îÄ‚îÄ design.md
‚îî‚îÄ‚îÄ specs/
    ‚îî‚îÄ‚îÄ core/
        ‚îî‚îÄ‚îÄ spec.md
```

## Task Creation Best Practices

### Task ID Naming

**Use verb-led kebab-case:**
- ‚úÖ `add-user-authentication`
- ‚úÖ `refactor-task-manager`
- ‚úÖ `update-api-validation`
- ‚úÖ `remove-legacy-code`
- ‚ùå `user-auth` (not descriptive)
- ‚ùå `task_manager` (use kebab-case)
- ‚ùå `new-feature` (too generic)

### Task Scope

**One capability per task:**
- ‚úÖ Good: `add-email-notifications`
- ‚ùå Bad: `add-email-notifications-and-sms-and-push` (too broad)

**Break large tasks into smaller ones:**
- ‚úÖ `add-email-notifications`
- ‚úÖ `add-sms-notifications`
- ‚úÖ `add-push-notifications`

### Task Checklist Structure

**Organize tasks by phase:**

```markdown
## 1. Planning & Design
- [ ] 1.1 Research existing solutions
- [ ] 1.2 Design architecture
- [ ] 1.3 Create technical spec

## 2. Implementation
- [ ] 2.1 Create core module
- [ ] 2.2 Add validation logic
- [ ] 2.3 Integrate with existing system

## 3. Testing
- [ ] 3.1 Write unit tests
- [ ] 3.2 Write integration tests
- [ ] 3.3 Test edge cases

## 4. Documentation
- [ ] 4.1 Update README
- [ ] 4.2 Update CHANGELOG
- [ ] 4.3 Add code comments

## 5. Cleanup
- [ ] 5.1 Remove debug code
- [ ] 5.2 Remove unused imports
- [ ] 5.3 Final code review
```

## Continuous Task Updates

**CRITICAL**: Update `tasks.md` continuously, not just at the end.

### Real-Time Updates

**Update as you work:**
1. **Start task**: Mark as `[ ]` (if not already)
2. **Begin implementation**: Add comment `<!-- in progress -->`
3. **Complete implementation**: Mark as `[x]`
4. **Test passes**: Add comment `<!-- tested -->`
5. **Ready for review**: Add comment `<!-- ready for review -->`

**Example:**
```markdown
## 1. Implementation
- [x] 1.1 Create task manager module <!-- tested -->
- [x] 1.2 Add validation logic <!-- tested, ready for review -->
- [ ] 1.3 Add archive functionality <!-- in progress -->
```

### Progress Tracking

**Add progress indicators:**
```markdown
## Progress: 60% (9/15 tasks complete)

## 1. Implementation Phase: 100% ‚úÖ
- [x] 1.1 Task 1
- [x] 1.2 Task 2
- [x] 1.3 Task 3

## 2. Testing Phase: 50% ‚è≥
- [x] 2.1 Unit tests
- [x] 2.2 Integration tests
- [ ] 2.3 E2E tests

## 3. Documentation Phase: 0% ‚è∏Ô∏è
- [ ] 3.1 README
- [ ] 3.2 CHANGELOG
- [ ] 3.3 API docs
```

## Task Validation Before Archive

**MANDATORY checks before archiving:**

```bash
# 1. Format validation
rulebook task validate <task-id>
# Must pass all format checks

# 2. Completion check
# All items in tasks.md must be [x]

# 3. Test coverage
npm test -- --coverage
# Must meet coverage thresholds

# 4. Code quality
npm run lint
npm run type-check
# Must pass all checks

# 5. Build verification
npm run build
# Must build successfully
```

## Summary: Task Lifecycle

**Complete task lifecycle:**

1. **Create** (MANDATORY FIRST STEP): `rulebook task create <task-id>`
   - ‚ö†Ô∏è NEVER start implementation without creating task first
   - ‚ö†Ô∏è Tasks without registration can be lost in context

2. **Plan**: Write proposal.md and tasks.md
   - Define why, what, and how
   - Create implementation checklist

3. **Design**: Write design.md (if needed)
   - Technical decisions
   - Architecture choices

4. **Spec**: Write spec deltas in specs/
   - OpenSpec-compatible format
   - Requirements with SHALL/MUST

5. **Validate**: `rulebook task validate <task-id>`
   - Format validation
   - Structure verification

6. **Implement**: Write code, following priority order
   - Most critical tasks first
   - Update tasks.md as you go

7. **Test** (HIGHEST PRIORITY): Write tests, verify coverage
   - All tests must pass
   - Coverage must meet thresholds
   - Mark tested items in tasks.md

8. **Update Status** (MANDATORY): Update task status before next task
   - Mark completed items as `[x]`
   - Update status in tasks.md
   - Verify status update

9. **Document**: Update docs, mark in tasks.md
   - README, CHANGELOG, specs

10. **Validate**: Final validation before archive
    - All checks pass
    - Coverage verified

11. **Archive**: `rulebook task archive <task-id>`
    - Move to archive
    - Apply spec deltas

**CRITICAL REMINDERS:**
- ‚ö†Ô∏è **ALWAYS create task BEFORE implementation** - without registration, tasks can be lost
- ‚ö†Ô∏è **ALWAYS follow priority order** - most critical first (tests, coverage, status update)
- ‚ö†Ô∏è **ALWAYS update task status before next task** - prevents context loss
- ‚ö†Ô∏è **ALWAYS verify coverage** - run `npm test -- --coverage` before marking complete
- ‚ö†Ô∏è **ALWAYS commit locally frequently** - even for backup, prevents work loss
- ‚ö†Ô∏è **ALWAYS keep remote repository updated** - push regularly if remote is configured
- ‚ö†Ô∏è **ALWAYS update `tasks.md` at EVERY step**, not just at the end!

## Best Practices

### DO's ‚úÖ

- **ALWAYS** create task BEFORE implementing any feature
- **ALWAYS** check Context7 MCP before creating tasks
- **ALWAYS** validate task format before committing
- **ALWAYS** use SHALL/MUST in requirements
- **ALWAYS** use 4 hashtags for scenarios
- **ALWAYS** use Given/When/Then structure
- **ALWAYS** follow priority order (most critical first)
- **ALWAYS** write tests first (highest priority)
- **ALWAYS** verify test coverage before marking complete
- **ALWAYS** commit locally frequently (even for backup)
- **ALWAYS** keep remote repository updated (push regularly)
- **ALWAYS** update task status before moving to next task
- **ALWAYS** update task status during implementation
- **ALWAYS** archive completed tasks
- **ALWAYS** document breaking changes in proposal

### DON'Ts ‚ùå

- **NEVER** start implementation without creating task first
- **NEVER** skip task registration (tasks can be lost in context)
- **NEVER** proceed to next task without updating current task status
- **NEVER** skip test coverage verification
- **NEVER** mark tasks complete without tests passing
- **NEVER** skip local commits (commit frequently for backup)
- **NEVER** let remote repository get out of sync (push regularly)
- **NEVER** commit sensitive information (API keys, passwords)
- **NEVER** force push to shared branches
- **NEVER** create tasks without checking Context7 format
- **NEVER** use 3 hashtags for scenarios
- **NEVER** omit SHALL/MUST from requirements
- **NEVER** use bullet points for scenarios
- **NEVER** skip validation
- **NEVER** leave tasks unarchived after completion
- **NEVER** mix formats (stick to OpenSpec-compatible format)
- **NEVER** ignore priority order (always do most critical first)

## CLI Commands Reference

### Task Management Commands

#### `rulebook task create <task-id>`

Create a new Rulebook task with OpenSpec-compatible format.

**Usage:**
```bash
rulebook task create add-user-authentication
```

**What it does:**
- Creates `/.rulebook/tasks/<task-id>/` directory
- Generates `proposal.md` template
- Generates `tasks.md` template
- Creates `specs/` directory for spec deltas

**Requirements:**
- Task ID must be unique (verb-led kebab-case)
- Context7 MCP must be available (for format validation)

**Example:**
```bash
$ rulebook task create add-email-notifications
‚úÖ Task add-email-notifications created successfully
Location: .rulebook/tasks/add-email-notifications/

‚ö†Ô∏è  Remember to:
  1. Check Context7 MCP for OpenSpec format requirements
  2. Fill in proposal.md (minimum 20 characters in "Why" section)
  3. Add tasks to tasks.md
  4. Create spec deltas in specs/*/spec.md
  5. Validate with: rulebook task validate add-email-notifications
```

**Error Handling:**
- `Task <task-id> already exists`: Choose a different task ID or archive existing task

---

#### `rulebook task list [--archived]`

List all Rulebook tasks (active and optionally archived).

**Usage:**
```bash
# List active tasks only
rulebook task list

# List including archived tasks
rulebook task list --archived
```

**Output:**
- Active tasks with status (pending, in-progress, completed, blocked)
- Archived tasks with archive date (if --archived flag is used)

**Example:**
```bash
$ rulebook task list

üìã Rulebook Tasks

Active Tasks:
  pending      add-user-authentication - Add user authentication feature
  in-progress  refactor-api-validation - Refactor API validation logic
  completed    update-documentation - Update project documentation

$ rulebook task list --archived

üìã Rulebook Tasks

Active Tasks:
  pending      add-user-authentication - Add user authentication feature

Archived Tasks:
  archived     2025-01-15-add-email-notifications - Add email notifications (2025-01-15)
```

**Task Status Values:**
- `pending`: Task not started
- `in-progress`: Task being worked on
- `completed`: Task finished (ready for archive)
- `blocked`: Task blocked by dependency

---

#### `rulebook task show <task-id>`

Show detailed information about a specific task.

**Usage:**
```bash
rulebook task show add-user-authentication
```

**Output:**
- Task ID and title
- Status (pending, in-progress, completed, blocked)
- Created and updated dates
- Archive date (if archived)
- Proposal summary (first 500 characters)
- Spec files list

**Example:**
```bash
$ rulebook task show add-user-authentication

üìã Task: add-user-authentication

Title: add-user-authentication
Status: pending
Created: 2025-01-15T10:30:00.000Z
Updated: 2025-01-15T10:30:00.000Z

Proposal:
# Proposal: Add User Authentication

## Why
We need to implement secure user authentication to protect user accounts and enable personalized features. This will include JWT token-based authentication with refresh tokens and password hashing using bcrypt...

Specs:
  core/spec.md (1234 chars)
```

**Error Handling:**
- `Task <task-id> not found`: Verify task ID exists with `rulebook task list`

---

#### `rulebook task validate <task-id>`

Validate task format against OpenSpec-compatible requirements.

**Usage:**
```bash
rulebook task validate add-user-authentication
```

**Validation Checks:**
- Purpose section length (‚â•20 characters)
- Requirement keywords (SHALL/MUST)
- Scenario format (4 hashtags, not 3)
- Given/When/Then structure
- Delta headers format (ADDED/MODIFIED/REMOVED/RENAMED)

**Example:**
```bash
$ rulebook task validate add-user-authentication
‚úÖ Task add-user-authentication is valid

‚ö†Ô∏è  Warnings:
  - Scenario in core/spec.md should use Given/When/Then structure
```

**Error Example:**
```bash
$ rulebook task validate invalid-task
‚ùå Task invalid-task validation failed

Errors:
  - Scenarios in core/spec.md must use 4 hashtags (####), not 3 (###)
  - Requirement in core/spec.md missing SHALL or MUST keyword: ### Requirement: Auth
  - Purpose section (## Why) must have at least 20 characters
```

**Error Handling:**
- Fix all errors before proceeding
- Warnings are informational but don't block archiving

---

#### `rulebook task archive <task-id> [--skip-validation]`

Archive a completed task and apply spec deltas to main specifications.

**Usage:**
```bash
# Archive with validation (recommended)
rulebook task archive add-user-authentication

# Archive without validation (use with caution)
rulebook task archive add-user-authentication --skip-validation
```

**Archive Process:**
1. Validates task format (unless `--skip-validation` is used)
2. Checks task completion status
3. Applies spec deltas to main specifications
4. Moves task to `/.rulebook/tasks/archive/YYYY-MM-DD-<task-id>/`
5. Updates related specifications

**Example:**
```bash
$ rulebook task archive add-user-authentication
‚úÖ Task add-user-authentication archived successfully
```

**Error Handling:**
- `Task validation failed`: Fix validation errors before archiving
- `Task <task-id> not found`: Verify task ID exists
- `Archive <archive-name> already exists`: Archive with that date already exists

**Important:**
- Only archive tasks that are fully completed
- All items in `tasks.md` should be marked as `[x]`
- All tests should pass
- Documentation should be updated

---

### Core Rulebook Commands

#### `rulebook init [--minimal] [--light] [--yes]`

Initialize Rulebook for current project.

**Usage:**
```bash
# Interactive mode
rulebook init

# Minimal setup (essentials only)
rulebook init --minimal

# Light mode (no quality enforcement)
rulebook init --light

# Skip prompts, use defaults
rulebook init --yes
```

**What it does:**
- Detects languages, frameworks, and MCP modules
- Generates AGENTS.md with AI assistant rules
- Creates `/rulebook/` directory with templates
- Creates/updates `.gitignore` automatically
- Optionally installs Git hooks
- Generates Cursor commands (if Cursor is selected IDE)

---

#### `rulebook update [--yes] [--minimal] [--light]`

Update AGENTS.md and .rulebook to latest version.

**Usage:**
```bash
# Interactive mode
rulebook update

# Skip confirmation
rulebook update --yes

# Minimal mode
rulebook update --minimal

# Light mode
rulebook update --light
```

**What it does:**
- Migrates OpenSpec tasks to Rulebook format (if OpenSpec exists)
- Migrates OpenSpec archives to Rulebook format
- Removes OpenSpec commands from `.cursor/commands/`
- Updates AGENTS.md with latest templates
- Merges templates while preserving customizations
- Updates Cursor commands (if Cursor is selected IDE)

---

#### `rulebook validate`

Validate project structure against Rulebook standards.

**Usage:**
```bash
rulebook validate
```

**Validation Checks:**
- AGENTS.md presence and format
- Rulebook directory structure
- Documentation structure
- Tests directory
- Score calculation (0-100)

---

#### `rulebook health`

Check project health score.

**Usage:**
```bash
rulebook health
```

**Categories Scored:**
- Quality (linting, formatting, code quality)
- Testing (test coverage, test quality)
- Security (vulnerabilities, secrets)
- Documentation (README, docs/, comments)

**Score Range:** 0-100

---

#### `rulebook workflows`

Generate GitHub Actions workflows for detected languages.

**Usage:**
```bash
rulebook workflows
```

**What it does:**
- Creates `.github/workflows/` directory
- Generates language-specific workflows (test, lint, publish)
- Adds codespell workflow for spelling checks

---

#### `rulebook check-deps`

Check for outdated and vulnerable dependencies.

**Usage:**
```bash
rulebook check-deps
```

**Supported Package Managers:**
- npm (package.json)
- Cargo (Cargo.toml)
- pip (requirements.txt, pyproject.toml)
- Go modules (go.mod)

---

#### `rulebook check-coverage [-t <threshold>]`

Check test coverage against threshold.

**Usage:**
```bash
# Default threshold (95%)
rulebook check-coverage

# Custom threshold
rulebook check-coverage -t 80
```

---

#### `rulebook generate-docs [--yes]`

Generate documentation structure and standard files.

**Usage:**
```bash
# Interactive mode
rulebook generate-docs

# Skip prompts
rulebook generate-docs --yes
```

---

#### `rulebook version <major|minor|patch>`

Bump project version (semantic versioning).

**Usage:**
```bash
rulebook version major  # 1.0.0 -> 2.0.0
rulebook version minor  # 1.0.0 -> 1.1.0
rulebook version patch  # 1.0.0 -> 1.0.1
```

---

#### `rulebook changelog [-v <version>]`

Generate changelog from git commits.

**Usage:**
```bash
# Auto-detect version
rulebook changelog

# Specify version
rulebook changelog -v 1.0.0
```

---

#### `rulebook fix`

Auto-fix common project issues.

**Usage:**
```bash
rulebook fix
```

---

### Advanced Commands (Beta)

#### `rulebook watcher`

Start modern full-screen console watcher for task progress.

**Usage:**
```bash
rulebook watcher
```

**Features:**
- Live task progress tracking
- Activity log with timestamps
- System status monitoring
- Auto-refresh every 2 seconds

---

#### `rulebook agent [--dry-run] [--tool <name>] [--iterations <n>] [--watch]`

Start autonomous agent for managing AI CLI workflows.

**Usage:**
```bash
# Dry run (simulate without changes)
rulebook agent --dry-run

# Specify CLI tool
rulebook agent --tool cursor-agent

# Set max iterations
rulebook agent --iterations 10

# Enable watcher mode
rulebook agent --watch
```

---

#### `rulebook config [--show] [--set <key=value>] [--feature <name> --enable|--disable]`

Manage Rulebook configuration.

**Usage:**
```bash
# Show current config
rulebook config --show

# Set config value
rulebook config --set rulebookDir=custom-rulebook

# Enable feature
rulebook config --feature watcher --enable

# Disable feature
rulebook config --feature agent --disable
```

## Migration from OpenSpec

If your project previously used OpenSpec:

1. **Automatic Migration**: Run `rulebook update` to automatically migrate OpenSpec tasks to Rulebook format
2. **Manual Migration**: Tasks in `/openspec/changes/` will be moved to `/.rulebook/tasks/`
3. **Format Compatibility**: Rulebook uses OpenSpec-compatible format, so existing tasks remain valid

## Context7 MCP Requirement

**CRITICAL**: Context7 MCP is REQUIRED for task creation.

**Why**: 
- Ensures correct format by fetching official OpenSpec documentation
- Prevents common format errors made by AI assistants
- Provides up-to-date format requirements

**If Context7 MCP is not available:**
- Task creation will fail with clear error message
- You must configure Context7 MCP before creating tasks
- See `/rulebook/CONTEXT7.md` for setup instructions

## Troubleshooting

### Validation Errors

**Error**: "Requirement must contain SHALL or MUST keyword"
- **Fix**: Add SHALL or MUST to requirement text
- **Example**: Change "The system provides authentication" to "The system SHALL provide authentication"

**Error**: "Scenario must use 4 hashtags"
- **Fix**: Change `### Scenario:` to `#### Scenario:` (at start of line)
- **Note**: Validation only checks headers at start of line, not in text content

**Error**: "Purpose section too short"
- **Fix**: Expand "Why" section in proposal.md to at least 20 characters
- **Example**: "Auth system" ‚Üí "Authentication system for secure user access with JWT tokens and session management"

**Error**: "Scenario must use Given/When/Then structure"
- **Fix**: Replace bullet points with Given/When/Then format
- **Example**: 
  ```markdown
  #### Scenario: User login
  Given a user has valid credentials
  When they submit the login form
  Then they are authenticated successfully
  ```

### Task Creation Errors

**Error**: "Context7 MCP not available"
- **Fix**: Configure Context7 MCP in your MCP configuration file
- **See**: `/rulebook/CONTEXT7.md` for setup instructions

**Error**: "Task ID already exists"
- **Fix**: Choose a different task ID or archive existing task
- **Check**: Use `rulebook task list` to see existing tasks

### Task Archive Errors

**Error**: "Task validation failed"
- **Fix**: Run `rulebook task validate <task-id>` to see all errors
- **Fix**: Address all validation errors before archiving
- **Option**: Use `--skip-validation` flag only if you're certain the task is valid

**Error**: "Archive <archive-name> already exists"
- **Fix**: Archive with that date already exists
- **Check**: Use `rulebook task list --archived` to see archived tasks

### Command Errors

**Error**: "Task <task-id> not found"
- **Fix**: Verify task ID exists with `rulebook task list`
- **Check**: Ensure you're in the correct project directory

**Error**: "No tasks found"
- **Fix**: Create a task first with `rulebook task create <task-id>`
- **Check**: Verify `/.rulebook/tasks/` directory exists

### Migration Errors

**Error**: "Failed to migrate task"
- **Fix**: Check error message for specific issue
- **Check**: Verify OpenSpec task structure is correct
- **Fix**: Manually migrate if automatic migration fails

**Error**: "Failed to read OpenSpec changes directory"
- **Fix**: Verify `/openspec/changes/` directory exists
- **Check**: Ensure you have read permissions

## Examples

See `/.rulebook/tasks/` directory for examples of correctly formatted tasks.

<!-- RULEBOOK:END -->


<!-- RULEBOOK:SKILL:core/rulebook:END -->
